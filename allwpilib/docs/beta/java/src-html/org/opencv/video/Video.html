<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc -->
<title>Source code</title>
<meta name="description" content="source: package: org.opencv.video, class: Video">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body class="source">
<main role="main">
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span><a id="line.1">//</a>
<span class="sourceLineNo">002</span><a id="line.2">// This file is auto-generated. Please don't modify it!</a>
<span class="sourceLineNo">003</span><a id="line.3">//</a>
<span class="sourceLineNo">004</span><a id="line.4">package org.opencv.video;</a>
<span class="sourceLineNo">005</span><a id="line.5"></a>
<span class="sourceLineNo">006</span><a id="line.6">import java.util.ArrayList;</a>
<span class="sourceLineNo">007</span><a id="line.7">import java.util.List;</a>
<span class="sourceLineNo">008</span><a id="line.8">import org.opencv.core.Mat;</a>
<span class="sourceLineNo">009</span><a id="line.9">import org.opencv.core.MatOfByte;</a>
<span class="sourceLineNo">010</span><a id="line.10">import org.opencv.core.MatOfFloat;</a>
<span class="sourceLineNo">011</span><a id="line.11">import org.opencv.core.MatOfPoint2f;</a>
<span class="sourceLineNo">012</span><a id="line.12">import org.opencv.core.Rect;</a>
<span class="sourceLineNo">013</span><a id="line.13">import org.opencv.core.RotatedRect;</a>
<span class="sourceLineNo">014</span><a id="line.14">import org.opencv.core.Size;</a>
<span class="sourceLineNo">015</span><a id="line.15">import org.opencv.core.TermCriteria;</a>
<span class="sourceLineNo">016</span><a id="line.16">import org.opencv.utils.Converters;</a>
<span class="sourceLineNo">017</span><a id="line.17">import org.opencv.video.BackgroundSubtractorKNN;</a>
<span class="sourceLineNo">018</span><a id="line.18">import org.opencv.video.BackgroundSubtractorMOG2;</a>
<span class="sourceLineNo">019</span><a id="line.19"></a>
<span class="sourceLineNo">020</span><a id="line.20">// C++: class Video</a>
<span class="sourceLineNo">021</span><a id="line.21"></a>
<span class="sourceLineNo">022</span><a id="line.22">public class Video {</a>
<span class="sourceLineNo">023</span><a id="line.23"></a>
<span class="sourceLineNo">024</span><a id="line.24">    private static final int</a>
<span class="sourceLineNo">025</span><a id="line.25">            CV_LKFLOW_INITIAL_GUESSES = 4,</a>
<span class="sourceLineNo">026</span><a id="line.26">            CV_LKFLOW_GET_MIN_EIGENVALS = 8;</a>
<span class="sourceLineNo">027</span><a id="line.27"></a>
<span class="sourceLineNo">028</span><a id="line.28"></a>
<span class="sourceLineNo">029</span><a id="line.29">    // C++: enum &lt;unnamed&gt;</a>
<span class="sourceLineNo">030</span><a id="line.30">    public static final int</a>
<span class="sourceLineNo">031</span><a id="line.31">            OPTFLOW_USE_INITIAL_FLOW = 4,</a>
<span class="sourceLineNo">032</span><a id="line.32">            OPTFLOW_LK_GET_MIN_EIGENVALS = 8,</a>
<span class="sourceLineNo">033</span><a id="line.33">            OPTFLOW_FARNEBACK_GAUSSIAN = 256,</a>
<span class="sourceLineNo">034</span><a id="line.34">            MOTION_TRANSLATION = 0,</a>
<span class="sourceLineNo">035</span><a id="line.35">            MOTION_EUCLIDEAN = 1,</a>
<span class="sourceLineNo">036</span><a id="line.36">            MOTION_AFFINE = 2,</a>
<span class="sourceLineNo">037</span><a id="line.37">            MOTION_HOMOGRAPHY = 3;</a>
<span class="sourceLineNo">038</span><a id="line.38"></a>
<span class="sourceLineNo">039</span><a id="line.39"></a>
<span class="sourceLineNo">040</span><a id="line.40">    // C++: enum MODE (cv.detail.TrackerSamplerCSC.MODE)</a>
<span class="sourceLineNo">041</span><a id="line.41">    public static final int</a>
<span class="sourceLineNo">042</span><a id="line.42">            TrackerSamplerCSC_MODE_INIT_POS = 1,</a>
<span class="sourceLineNo">043</span><a id="line.43">            TrackerSamplerCSC_MODE_INIT_NEG = 2,</a>
<span class="sourceLineNo">044</span><a id="line.44">            TrackerSamplerCSC_MODE_TRACK_POS = 3,</a>
<span class="sourceLineNo">045</span><a id="line.45">            TrackerSamplerCSC_MODE_TRACK_NEG = 4,</a>
<span class="sourceLineNo">046</span><a id="line.46">            TrackerSamplerCSC_MODE_DETECT = 5;</a>
<span class="sourceLineNo">047</span><a id="line.47"></a>
<span class="sourceLineNo">048</span><a id="line.48"></a>
<span class="sourceLineNo">049</span><a id="line.49">    //</a>
<span class="sourceLineNo">050</span><a id="line.50">    // C++:  Ptr_BackgroundSubtractorMOG2 cv::createBackgroundSubtractorMOG2(int history = 500, double varThreshold = 16, bool detectShadows = true)</a>
<span class="sourceLineNo">051</span><a id="line.51">    //</a>
<span class="sourceLineNo">052</span><a id="line.52"></a>
<span class="sourceLineNo">053</span><a id="line.53">    /**</a>
<span class="sourceLineNo">054</span><a id="line.54">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">055</span><a id="line.55">     *</a>
<span class="sourceLineNo">056</span><a id="line.56">     * @param history Length of the history.</a>
<span class="sourceLineNo">057</span><a id="line.57">     * @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model</a>
<span class="sourceLineNo">058</span><a id="line.58">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">059</span><a id="line.59">     * affect the background update.</a>
<span class="sourceLineNo">060</span><a id="line.60">     * @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the</a>
<span class="sourceLineNo">061</span><a id="line.61">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">062</span><a id="line.62">     * @return automatically generated</a>
<span class="sourceLineNo">063</span><a id="line.63">     */</a>
<span class="sourceLineNo">064</span><a id="line.64">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2(int history, double varThreshold, boolean detectShadows) {</a>
<span class="sourceLineNo">065</span><a id="line.65">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_0(history, varThreshold, detectShadows));</a>
<span class="sourceLineNo">066</span><a id="line.66">    }</a>
<span class="sourceLineNo">067</span><a id="line.67"></a>
<span class="sourceLineNo">068</span><a id="line.68">    /**</a>
<span class="sourceLineNo">069</span><a id="line.69">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">070</span><a id="line.70">     *</a>
<span class="sourceLineNo">071</span><a id="line.71">     * @param history Length of the history.</a>
<span class="sourceLineNo">072</span><a id="line.72">     * @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model</a>
<span class="sourceLineNo">073</span><a id="line.73">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">074</span><a id="line.74">     * affect the background update.</a>
<span class="sourceLineNo">075</span><a id="line.75">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">076</span><a id="line.76">     * @return automatically generated</a>
<span class="sourceLineNo">077</span><a id="line.77">     */</a>
<span class="sourceLineNo">078</span><a id="line.78">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2(int history, double varThreshold) {</a>
<span class="sourceLineNo">079</span><a id="line.79">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_1(history, varThreshold));</a>
<span class="sourceLineNo">080</span><a id="line.80">    }</a>
<span class="sourceLineNo">081</span><a id="line.81"></a>
<span class="sourceLineNo">082</span><a id="line.82">    /**</a>
<span class="sourceLineNo">083</span><a id="line.83">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">084</span><a id="line.84">     *</a>
<span class="sourceLineNo">085</span><a id="line.85">     * @param history Length of the history.</a>
<span class="sourceLineNo">086</span><a id="line.86">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">087</span><a id="line.87">     * affect the background update.</a>
<span class="sourceLineNo">088</span><a id="line.88">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">089</span><a id="line.89">     * @return automatically generated</a>
<span class="sourceLineNo">090</span><a id="line.90">     */</a>
<span class="sourceLineNo">091</span><a id="line.91">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2(int history) {</a>
<span class="sourceLineNo">092</span><a id="line.92">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_2(history));</a>
<span class="sourceLineNo">093</span><a id="line.93">    }</a>
<span class="sourceLineNo">094</span><a id="line.94"></a>
<span class="sourceLineNo">095</span><a id="line.95">    /**</a>
<span class="sourceLineNo">096</span><a id="line.96">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">097</span><a id="line.97">     *</a>
<span class="sourceLineNo">098</span><a id="line.98">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">099</span><a id="line.99">     * affect the background update.</a>
<span class="sourceLineNo">100</span><a id="line.100">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">101</span><a id="line.101">     * @return automatically generated</a>
<span class="sourceLineNo">102</span><a id="line.102">     */</a>
<span class="sourceLineNo">103</span><a id="line.103">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2() {</a>
<span class="sourceLineNo">104</span><a id="line.104">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_3());</a>
<span class="sourceLineNo">105</span><a id="line.105">    }</a>
<span class="sourceLineNo">106</span><a id="line.106"></a>
<span class="sourceLineNo">107</span><a id="line.107"></a>
<span class="sourceLineNo">108</span><a id="line.108">    //</a>
<span class="sourceLineNo">109</span><a id="line.109">    // C++:  Ptr_BackgroundSubtractorKNN cv::createBackgroundSubtractorKNN(int history = 500, double dist2Threshold = 400.0, bool detectShadows = true)</a>
<span class="sourceLineNo">110</span><a id="line.110">    //</a>
<span class="sourceLineNo">111</span><a id="line.111"></a>
<span class="sourceLineNo">112</span><a id="line.112">    /**</a>
<span class="sourceLineNo">113</span><a id="line.113">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">114</span><a id="line.114">     *</a>
<span class="sourceLineNo">115</span><a id="line.115">     * @param history Length of the history.</a>
<span class="sourceLineNo">116</span><a id="line.116">     * @param dist2Threshold Threshold on the squared distance between the pixel and the sample to decide</a>
<span class="sourceLineNo">117</span><a id="line.117">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">118</span><a id="line.118">     * @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the</a>
<span class="sourceLineNo">119</span><a id="line.119">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">120</span><a id="line.120">     * @return automatically generated</a>
<span class="sourceLineNo">121</span><a id="line.121">     */</a>
<span class="sourceLineNo">122</span><a id="line.122">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN(int history, double dist2Threshold, boolean detectShadows) {</a>
<span class="sourceLineNo">123</span><a id="line.123">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_0(history, dist2Threshold, detectShadows));</a>
<span class="sourceLineNo">124</span><a id="line.124">    }</a>
<span class="sourceLineNo">125</span><a id="line.125"></a>
<span class="sourceLineNo">126</span><a id="line.126">    /**</a>
<span class="sourceLineNo">127</span><a id="line.127">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">128</span><a id="line.128">     *</a>
<span class="sourceLineNo">129</span><a id="line.129">     * @param history Length of the history.</a>
<span class="sourceLineNo">130</span><a id="line.130">     * @param dist2Threshold Threshold on the squared distance between the pixel and the sample to decide</a>
<span class="sourceLineNo">131</span><a id="line.131">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">132</span><a id="line.132">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">133</span><a id="line.133">     * @return automatically generated</a>
<span class="sourceLineNo">134</span><a id="line.134">     */</a>
<span class="sourceLineNo">135</span><a id="line.135">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN(int history, double dist2Threshold) {</a>
<span class="sourceLineNo">136</span><a id="line.136">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_1(history, dist2Threshold));</a>
<span class="sourceLineNo">137</span><a id="line.137">    }</a>
<span class="sourceLineNo">138</span><a id="line.138"></a>
<span class="sourceLineNo">139</span><a id="line.139">    /**</a>
<span class="sourceLineNo">140</span><a id="line.140">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">141</span><a id="line.141">     *</a>
<span class="sourceLineNo">142</span><a id="line.142">     * @param history Length of the history.</a>
<span class="sourceLineNo">143</span><a id="line.143">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">144</span><a id="line.144">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">145</span><a id="line.145">     * @return automatically generated</a>
<span class="sourceLineNo">146</span><a id="line.146">     */</a>
<span class="sourceLineNo">147</span><a id="line.147">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN(int history) {</a>
<span class="sourceLineNo">148</span><a id="line.148">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_2(history));</a>
<span class="sourceLineNo">149</span><a id="line.149">    }</a>
<span class="sourceLineNo">150</span><a id="line.150"></a>
<span class="sourceLineNo">151</span><a id="line.151">    /**</a>
<span class="sourceLineNo">152</span><a id="line.152">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">153</span><a id="line.153">     *</a>
<span class="sourceLineNo">154</span><a id="line.154">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">155</span><a id="line.155">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">156</span><a id="line.156">     * @return automatically generated</a>
<span class="sourceLineNo">157</span><a id="line.157">     */</a>
<span class="sourceLineNo">158</span><a id="line.158">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN() {</a>
<span class="sourceLineNo">159</span><a id="line.159">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_3());</a>
<span class="sourceLineNo">160</span><a id="line.160">    }</a>
<span class="sourceLineNo">161</span><a id="line.161"></a>
<span class="sourceLineNo">162</span><a id="line.162"></a>
<span class="sourceLineNo">163</span><a id="line.163">    //</a>
<span class="sourceLineNo">164</span><a id="line.164">    // C++:  RotatedRect cv::CamShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">165</span><a id="line.165">    //</a>
<span class="sourceLineNo">166</span><a id="line.166"></a>
<span class="sourceLineNo">167</span><a id="line.167">    /**</a>
<span class="sourceLineNo">168</span><a id="line.168">     * Finds an object center, size, and orientation.</a>
<span class="sourceLineNo">169</span><a id="line.169">     *</a>
<span class="sourceLineNo">170</span><a id="line.170">     * @param probImage Back projection of the object histogram. See calcBackProject.</a>
<span class="sourceLineNo">171</span><a id="line.171">     * @param window Initial search window.</a>
<span class="sourceLineNo">172</span><a id="line.172">     * @param criteria Stop criteria for the underlying meanShift.</a>
<span class="sourceLineNo">173</span><a id="line.173">     * returns</a>
<span class="sourceLineNo">174</span><a id="line.174">     * (in old interfaces) Number of iterations CAMSHIFT took to converge</a>
<span class="sourceLineNo">175</span><a id="line.175">     * The function implements the CAMSHIFT object tracking algorithm CITE: Bradski98 . First, it finds an</a>
<span class="sourceLineNo">176</span><a id="line.176">     * object center using meanShift and then adjusts the window size and finds the optimal rotation. The</a>
<span class="sourceLineNo">177</span><a id="line.177">     * function returns the rotated rectangle structure that includes the object position, size, and</a>
<span class="sourceLineNo">178</span><a id="line.178">     * orientation. The next position of the search window can be obtained with RotatedRect::boundingRect()</a>
<span class="sourceLineNo">179</span><a id="line.179">     *</a>
<span class="sourceLineNo">180</span><a id="line.180">     * See the OpenCV sample camshiftdemo.c that tracks colored objects.</a>
<span class="sourceLineNo">181</span><a id="line.181">     *</a>
<span class="sourceLineNo">182</span><a id="line.182">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">183</span><a id="line.183">     * &lt;ul&gt;</a>
<span class="sourceLineNo">184</span><a id="line.184">     *   &lt;li&gt;</a>
<span class="sourceLineNo">185</span><a id="line.185">     *    (Python) A sample explaining the camshift tracking algorithm can be found at</a>
<span class="sourceLineNo">186</span><a id="line.186">     *     opencv_source_code/samples/python/camshift.py</a>
<span class="sourceLineNo">187</span><a id="line.187">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">188</span><a id="line.188">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">189</span><a id="line.189">     * @return automatically generated</a>
<span class="sourceLineNo">190</span><a id="line.190">     */</a>
<span class="sourceLineNo">191</span><a id="line.191">    public static RotatedRect CamShift(Mat probImage, Rect window, TermCriteria criteria) {</a>
<span class="sourceLineNo">192</span><a id="line.192">        double[] window_out = new double[4];</a>
<span class="sourceLineNo">193</span><a id="line.193">        RotatedRect retVal = new RotatedRect(CamShift_0(probImage.nativeObj, window.x, window.y, window.width, window.height, window_out, criteria.type, criteria.maxCount, criteria.epsilon));</a>
<span class="sourceLineNo">194</span><a id="line.194">        if(window!=null){ window.x = (int)window_out[0]; window.y = (int)window_out[1]; window.width = (int)window_out[2]; window.height = (int)window_out[3]; } </a>
<span class="sourceLineNo">195</span><a id="line.195">        return retVal;</a>
<span class="sourceLineNo">196</span><a id="line.196">    }</a>
<span class="sourceLineNo">197</span><a id="line.197"></a>
<span class="sourceLineNo">198</span><a id="line.198"></a>
<span class="sourceLineNo">199</span><a id="line.199">    //</a>
<span class="sourceLineNo">200</span><a id="line.200">    // C++:  int cv::meanShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">201</span><a id="line.201">    //</a>
<span class="sourceLineNo">202</span><a id="line.202"></a>
<span class="sourceLineNo">203</span><a id="line.203">    /**</a>
<span class="sourceLineNo">204</span><a id="line.204">     * Finds an object on a back projection image.</a>
<span class="sourceLineNo">205</span><a id="line.205">     *</a>
<span class="sourceLineNo">206</span><a id="line.206">     * @param probImage Back projection of the object histogram. See calcBackProject for details.</a>
<span class="sourceLineNo">207</span><a id="line.207">     * @param window Initial search window.</a>
<span class="sourceLineNo">208</span><a id="line.208">     * @param criteria Stop criteria for the iterative search algorithm.</a>
<span class="sourceLineNo">209</span><a id="line.209">     * returns</a>
<span class="sourceLineNo">210</span><a id="line.210">     * :   Number of iterations CAMSHIFT took to converge.</a>
<span class="sourceLineNo">211</span><a id="line.211">     * The function implements the iterative object search algorithm. It takes the input back projection of</a>
<span class="sourceLineNo">212</span><a id="line.212">     * an object and the initial position. The mass center in window of the back projection image is</a>
<span class="sourceLineNo">213</span><a id="line.213">     * computed and the search window center shifts to the mass center. The procedure is repeated until the</a>
<span class="sourceLineNo">214</span><a id="line.214">     * specified number of iterations criteria.maxCount is done or until the window center shifts by less</a>
<span class="sourceLineNo">215</span><a id="line.215">     * than criteria.epsilon. The algorithm is used inside CamShift and, unlike CamShift , the search</a>
<span class="sourceLineNo">216</span><a id="line.216">     * window size or orientation do not change during the search. You can simply pass the output of</a>
<span class="sourceLineNo">217</span><a id="line.217">     * calcBackProject to this function. But better results can be obtained if you pre-filter the back</a>
<span class="sourceLineNo">218</span><a id="line.218">     * projection and remove the noise. For example, you can do this by retrieving connected components</a>
<span class="sourceLineNo">219</span><a id="line.219">     * with findContours , throwing away contours with small area ( contourArea ), and rendering the</a>
<span class="sourceLineNo">220</span><a id="line.220">     * remaining contours with drawContours.</a>
<span class="sourceLineNo">221</span><a id="line.221">     * @return automatically generated</a>
<span class="sourceLineNo">222</span><a id="line.222">     */</a>
<span class="sourceLineNo">223</span><a id="line.223">    public static int meanShift(Mat probImage, Rect window, TermCriteria criteria) {</a>
<span class="sourceLineNo">224</span><a id="line.224">        double[] window_out = new double[4];</a>
<span class="sourceLineNo">225</span><a id="line.225">        int retVal = meanShift_0(probImage.nativeObj, window.x, window.y, window.width, window.height, window_out, criteria.type, criteria.maxCount, criteria.epsilon);</a>
<span class="sourceLineNo">226</span><a id="line.226">        if(window!=null){ window.x = (int)window_out[0]; window.y = (int)window_out[1]; window.width = (int)window_out[2]; window.height = (int)window_out[3]; } </a>
<span class="sourceLineNo">227</span><a id="line.227">        return retVal;</a>
<span class="sourceLineNo">228</span><a id="line.228">    }</a>
<span class="sourceLineNo">229</span><a id="line.229"></a>
<span class="sourceLineNo">230</span><a id="line.230"></a>
<span class="sourceLineNo">231</span><a id="line.231">    //</a>
<span class="sourceLineNo">232</span><a id="line.232">    // C++:  int cv::buildOpticalFlowPyramid(Mat img, vector_Mat&amp; pyramid, Size winSize, int maxLevel, bool withDerivatives = true, int pyrBorder = BORDER_REFLECT_101, int derivBorder = BORDER_CONSTANT, bool tryReuseInputImage = true)</a>
<span class="sourceLineNo">233</span><a id="line.233">    //</a>
<span class="sourceLineNo">234</span><a id="line.234"></a>
<span class="sourceLineNo">235</span><a id="line.235">    /**</a>
<span class="sourceLineNo">236</span><a id="line.236">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">237</span><a id="line.237">     *</a>
<span class="sourceLineNo">238</span><a id="line.238">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">239</span><a id="line.239">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">240</span><a id="line.240">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">241</span><a id="line.241">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">242</span><a id="line.242">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">243</span><a id="line.243">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">244</span><a id="line.244">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">245</span><a id="line.245">     * @param pyrBorder the border mode for pyramid layers.</a>
<span class="sourceLineNo">246</span><a id="line.246">     * @param derivBorder the border mode for gradients.</a>
<span class="sourceLineNo">247</span><a id="line.247">     * @param tryReuseInputImage put ROI of input image into the pyramid if possible. You can pass false</a>
<span class="sourceLineNo">248</span><a id="line.248">     * to force data copying.</a>
<span class="sourceLineNo">249</span><a id="line.249">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">250</span><a id="line.250">     */</a>
<span class="sourceLineNo">251</span><a id="line.251">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder, boolean tryReuseInputImage) {</a>
<span class="sourceLineNo">252</span><a id="line.252">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">253</span><a id="line.253">        int retVal = buildOpticalFlowPyramid_0(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives, pyrBorder, derivBorder, tryReuseInputImage);</a>
<span class="sourceLineNo">254</span><a id="line.254">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">255</span><a id="line.255">        pyramid_mat.release();</a>
<span class="sourceLineNo">256</span><a id="line.256">        return retVal;</a>
<span class="sourceLineNo">257</span><a id="line.257">    }</a>
<span class="sourceLineNo">258</span><a id="line.258"></a>
<span class="sourceLineNo">259</span><a id="line.259">    /**</a>
<span class="sourceLineNo">260</span><a id="line.260">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">261</span><a id="line.261">     *</a>
<span class="sourceLineNo">262</span><a id="line.262">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">263</span><a id="line.263">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">264</span><a id="line.264">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">265</span><a id="line.265">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">266</span><a id="line.266">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">267</span><a id="line.267">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">268</span><a id="line.268">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">269</span><a id="line.269">     * @param pyrBorder the border mode for pyramid layers.</a>
<span class="sourceLineNo">270</span><a id="line.270">     * @param derivBorder the border mode for gradients.</a>
<span class="sourceLineNo">271</span><a id="line.271">     * to force data copying.</a>
<span class="sourceLineNo">272</span><a id="line.272">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">273</span><a id="line.273">     */</a>
<span class="sourceLineNo">274</span><a id="line.274">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder) {</a>
<span class="sourceLineNo">275</span><a id="line.275">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">276</span><a id="line.276">        int retVal = buildOpticalFlowPyramid_1(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives, pyrBorder, derivBorder);</a>
<span class="sourceLineNo">277</span><a id="line.277">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">278</span><a id="line.278">        pyramid_mat.release();</a>
<span class="sourceLineNo">279</span><a id="line.279">        return retVal;</a>
<span class="sourceLineNo">280</span><a id="line.280">    }</a>
<span class="sourceLineNo">281</span><a id="line.281"></a>
<span class="sourceLineNo">282</span><a id="line.282">    /**</a>
<span class="sourceLineNo">283</span><a id="line.283">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">284</span><a id="line.284">     *</a>
<span class="sourceLineNo">285</span><a id="line.285">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">286</span><a id="line.286">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">287</span><a id="line.287">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">288</span><a id="line.288">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">289</span><a id="line.289">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">290</span><a id="line.290">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">291</span><a id="line.291">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">292</span><a id="line.292">     * @param pyrBorder the border mode for pyramid layers.</a>
<span class="sourceLineNo">293</span><a id="line.293">     * to force data copying.</a>
<span class="sourceLineNo">294</span><a id="line.294">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">295</span><a id="line.295">     */</a>
<span class="sourceLineNo">296</span><a id="line.296">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives, int pyrBorder) {</a>
<span class="sourceLineNo">297</span><a id="line.297">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">298</span><a id="line.298">        int retVal = buildOpticalFlowPyramid_2(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives, pyrBorder);</a>
<span class="sourceLineNo">299</span><a id="line.299">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">300</span><a id="line.300">        pyramid_mat.release();</a>
<span class="sourceLineNo">301</span><a id="line.301">        return retVal;</a>
<span class="sourceLineNo">302</span><a id="line.302">    }</a>
<span class="sourceLineNo">303</span><a id="line.303"></a>
<span class="sourceLineNo">304</span><a id="line.304">    /**</a>
<span class="sourceLineNo">305</span><a id="line.305">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">306</span><a id="line.306">     *</a>
<span class="sourceLineNo">307</span><a id="line.307">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">308</span><a id="line.308">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">309</span><a id="line.309">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">310</span><a id="line.310">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">311</span><a id="line.311">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">312</span><a id="line.312">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">313</span><a id="line.313">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">314</span><a id="line.314">     * to force data copying.</a>
<span class="sourceLineNo">315</span><a id="line.315">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">316</span><a id="line.316">     */</a>
<span class="sourceLineNo">317</span><a id="line.317">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives) {</a>
<span class="sourceLineNo">318</span><a id="line.318">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">319</span><a id="line.319">        int retVal = buildOpticalFlowPyramid_3(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives);</a>
<span class="sourceLineNo">320</span><a id="line.320">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">321</span><a id="line.321">        pyramid_mat.release();</a>
<span class="sourceLineNo">322</span><a id="line.322">        return retVal;</a>
<span class="sourceLineNo">323</span><a id="line.323">    }</a>
<span class="sourceLineNo">324</span><a id="line.324"></a>
<span class="sourceLineNo">325</span><a id="line.325">    /**</a>
<span class="sourceLineNo">326</span><a id="line.326">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">327</span><a id="line.327">     *</a>
<span class="sourceLineNo">328</span><a id="line.328">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">329</span><a id="line.329">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">330</span><a id="line.330">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">331</span><a id="line.331">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">332</span><a id="line.332">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">333</span><a id="line.333">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">334</span><a id="line.334">     * to force data copying.</a>
<span class="sourceLineNo">335</span><a id="line.335">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">336</span><a id="line.336">     */</a>
<span class="sourceLineNo">337</span><a id="line.337">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel) {</a>
<span class="sourceLineNo">338</span><a id="line.338">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">339</span><a id="line.339">        int retVal = buildOpticalFlowPyramid_4(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel);</a>
<span class="sourceLineNo">340</span><a id="line.340">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">341</span><a id="line.341">        pyramid_mat.release();</a>
<span class="sourceLineNo">342</span><a id="line.342">        return retVal;</a>
<span class="sourceLineNo">343</span><a id="line.343">    }</a>
<span class="sourceLineNo">344</span><a id="line.344"></a>
<span class="sourceLineNo">345</span><a id="line.345"></a>
<span class="sourceLineNo">346</span><a id="line.346">    //</a>
<span class="sourceLineNo">347</span><a id="line.347">    // C++:  void cv::calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, vector_Point2f prevPts, vector_Point2f&amp; nextPts, vector_uchar&amp; status, vector_float&amp; err, Size winSize = Size(21,21), int maxLevel = 3, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01), int flags = 0, double minEigThreshold = 1e-4)</a>
<span class="sourceLineNo">348</span><a id="line.348">    //</a>
<span class="sourceLineNo">349</span><a id="line.349"></a>
<span class="sourceLineNo">350</span><a id="line.350">    /**</a>
<span class="sourceLineNo">351</span><a id="line.351">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">352</span><a id="line.352">     * pyramids.</a>
<span class="sourceLineNo">353</span><a id="line.353">     *</a>
<span class="sourceLineNo">354</span><a id="line.354">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">355</span><a id="line.355">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">356</span><a id="line.356">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">357</span><a id="line.357">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">358</span><a id="line.358">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">359</span><a id="line.359">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">360</span><a id="line.360">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">361</span><a id="line.361">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">362</span><a id="line.362">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">363</span><a id="line.363">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">364</span><a id="line.364">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">365</span><a id="line.365">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">366</span><a id="line.366">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">367</span><a id="line.367">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">368</span><a id="line.368">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">369</span><a id="line.369">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">370</span><a id="line.370">     * @param criteria parameter, specifying the termination criteria of the iterative search algorithm</a>
<span class="sourceLineNo">371</span><a id="line.371">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">372</span><a id="line.372">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">373</span><a id="line.373">     * @param flags operation flags:</a>
<span class="sourceLineNo">374</span><a id="line.374">     * &lt;ul&gt;</a>
<span class="sourceLineNo">375</span><a id="line.375">     *   &lt;li&gt;</a>
<span class="sourceLineNo">376</span><a id="line.376">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">377</span><a id="line.377">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">378</span><a id="line.378">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">379</span><a id="line.379">     *   &lt;li&gt;</a>
<span class="sourceLineNo">380</span><a id="line.380">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">381</span><a id="line.381">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">382</span><a id="line.382">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">383</span><a id="line.383">     *      error measure.</a>
<span class="sourceLineNo">384</span><a id="line.384">     * @param minEigThreshold the algorithm calculates the minimum eigen value of a 2x2 normal matrix of</a>
<span class="sourceLineNo">385</span><a id="line.385">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">386</span><a id="line.386">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">387</span><a id="line.387">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">388</span><a id="line.388">     * performance boost.</a>
<span class="sourceLineNo">389</span><a id="line.389">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">390</span><a id="line.390">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">391</span><a id="line.391">     *</a>
<span class="sourceLineNo">392</span><a id="line.392">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">393</span><a id="line.393">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">394</span><a id="line.394">     *</a>
<span class="sourceLineNo">395</span><a id="line.395">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">396</span><a id="line.396">     *</a>
<span class="sourceLineNo">397</span><a id="line.397">     * &lt;ul&gt;</a>
<span class="sourceLineNo">398</span><a id="line.398">     *   &lt;li&gt;</a>
<span class="sourceLineNo">399</span><a id="line.399">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">400</span><a id="line.400">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">401</span><a id="line.401">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">402</span><a id="line.402">     *   &lt;li&gt;</a>
<span class="sourceLineNo">403</span><a id="line.403">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">404</span><a id="line.404">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">405</span><a id="line.405">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">406</span><a id="line.406">     *   &lt;li&gt;</a>
<span class="sourceLineNo">407</span><a id="line.407">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">408</span><a id="line.408">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">409</span><a id="line.409">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">410</span><a id="line.410">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">411</span><a id="line.411">     */</a>
<span class="sourceLineNo">412</span><a id="line.412">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel, TermCriteria criteria, int flags, double minEigThreshold) {</a>
<span class="sourceLineNo">413</span><a id="line.413">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">414</span><a id="line.414">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">415</span><a id="line.415">        Mat status_mat = status;</a>
<span class="sourceLineNo">416</span><a id="line.416">        Mat err_mat = err;</a>
<span class="sourceLineNo">417</span><a id="line.417">        calcOpticalFlowPyrLK_0(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel, criteria.type, criteria.maxCount, criteria.epsilon, flags, minEigThreshold);</a>
<span class="sourceLineNo">418</span><a id="line.418">    }</a>
<span class="sourceLineNo">419</span><a id="line.419"></a>
<span class="sourceLineNo">420</span><a id="line.420">    /**</a>
<span class="sourceLineNo">421</span><a id="line.421">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">422</span><a id="line.422">     * pyramids.</a>
<span class="sourceLineNo">423</span><a id="line.423">     *</a>
<span class="sourceLineNo">424</span><a id="line.424">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">425</span><a id="line.425">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">426</span><a id="line.426">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">427</span><a id="line.427">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">428</span><a id="line.428">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">429</span><a id="line.429">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">430</span><a id="line.430">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">431</span><a id="line.431">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">432</span><a id="line.432">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">433</span><a id="line.433">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">434</span><a id="line.434">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">435</span><a id="line.435">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">436</span><a id="line.436">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">437</span><a id="line.437">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">438</span><a id="line.438">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">439</span><a id="line.439">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">440</span><a id="line.440">     * @param criteria parameter, specifying the termination criteria of the iterative search algorithm</a>
<span class="sourceLineNo">441</span><a id="line.441">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">442</span><a id="line.442">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">443</span><a id="line.443">     * @param flags operation flags:</a>
<span class="sourceLineNo">444</span><a id="line.444">     * &lt;ul&gt;</a>
<span class="sourceLineNo">445</span><a id="line.445">     *   &lt;li&gt;</a>
<span class="sourceLineNo">446</span><a id="line.446">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">447</span><a id="line.447">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">448</span><a id="line.448">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">449</span><a id="line.449">     *   &lt;li&gt;</a>
<span class="sourceLineNo">450</span><a id="line.450">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">451</span><a id="line.451">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">452</span><a id="line.452">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">453</span><a id="line.453">     *      error measure.</a>
<span class="sourceLineNo">454</span><a id="line.454">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">455</span><a id="line.455">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">456</span><a id="line.456">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">457</span><a id="line.457">     * performance boost.</a>
<span class="sourceLineNo">458</span><a id="line.458">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">459</span><a id="line.459">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">460</span><a id="line.460">     *</a>
<span class="sourceLineNo">461</span><a id="line.461">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">462</span><a id="line.462">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">463</span><a id="line.463">     *</a>
<span class="sourceLineNo">464</span><a id="line.464">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">465</span><a id="line.465">     *</a>
<span class="sourceLineNo">466</span><a id="line.466">     * &lt;ul&gt;</a>
<span class="sourceLineNo">467</span><a id="line.467">     *   &lt;li&gt;</a>
<span class="sourceLineNo">468</span><a id="line.468">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">469</span><a id="line.469">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">470</span><a id="line.470">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">471</span><a id="line.471">     *   &lt;li&gt;</a>
<span class="sourceLineNo">472</span><a id="line.472">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">473</span><a id="line.473">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">474</span><a id="line.474">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">475</span><a id="line.475">     *   &lt;li&gt;</a>
<span class="sourceLineNo">476</span><a id="line.476">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">477</span><a id="line.477">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">478</span><a id="line.478">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">479</span><a id="line.479">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">480</span><a id="line.480">     */</a>
<span class="sourceLineNo">481</span><a id="line.481">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel, TermCriteria criteria, int flags) {</a>
<span class="sourceLineNo">482</span><a id="line.482">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">483</span><a id="line.483">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">484</span><a id="line.484">        Mat status_mat = status;</a>
<span class="sourceLineNo">485</span><a id="line.485">        Mat err_mat = err;</a>
<span class="sourceLineNo">486</span><a id="line.486">        calcOpticalFlowPyrLK_1(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel, criteria.type, criteria.maxCount, criteria.epsilon, flags);</a>
<span class="sourceLineNo">487</span><a id="line.487">    }</a>
<span class="sourceLineNo">488</span><a id="line.488"></a>
<span class="sourceLineNo">489</span><a id="line.489">    /**</a>
<span class="sourceLineNo">490</span><a id="line.490">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">491</span><a id="line.491">     * pyramids.</a>
<span class="sourceLineNo">492</span><a id="line.492">     *</a>
<span class="sourceLineNo">493</span><a id="line.493">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">494</span><a id="line.494">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">495</span><a id="line.495">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">496</span><a id="line.496">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">497</span><a id="line.497">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">498</span><a id="line.498">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">499</span><a id="line.499">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">500</span><a id="line.500">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">501</span><a id="line.501">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">502</span><a id="line.502">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">503</span><a id="line.503">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">504</span><a id="line.504">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">505</span><a id="line.505">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">506</span><a id="line.506">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">507</span><a id="line.507">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">508</span><a id="line.508">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">509</span><a id="line.509">     * @param criteria parameter, specifying the termination criteria of the iterative search algorithm</a>
<span class="sourceLineNo">510</span><a id="line.510">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">511</span><a id="line.511">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">512</span><a id="line.512">     * &lt;ul&gt;</a>
<span class="sourceLineNo">513</span><a id="line.513">     *   &lt;li&gt;</a>
<span class="sourceLineNo">514</span><a id="line.514">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">515</span><a id="line.515">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">516</span><a id="line.516">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">517</span><a id="line.517">     *   &lt;li&gt;</a>
<span class="sourceLineNo">518</span><a id="line.518">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">519</span><a id="line.519">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">520</span><a id="line.520">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">521</span><a id="line.521">     *      error measure.</a>
<span class="sourceLineNo">522</span><a id="line.522">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">523</span><a id="line.523">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">524</span><a id="line.524">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">525</span><a id="line.525">     * performance boost.</a>
<span class="sourceLineNo">526</span><a id="line.526">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">527</span><a id="line.527">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">528</span><a id="line.528">     *</a>
<span class="sourceLineNo">529</span><a id="line.529">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">530</span><a id="line.530">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">531</span><a id="line.531">     *</a>
<span class="sourceLineNo">532</span><a id="line.532">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">533</span><a id="line.533">     *</a>
<span class="sourceLineNo">534</span><a id="line.534">     * &lt;ul&gt;</a>
<span class="sourceLineNo">535</span><a id="line.535">     *   &lt;li&gt;</a>
<span class="sourceLineNo">536</span><a id="line.536">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">537</span><a id="line.537">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">538</span><a id="line.538">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">539</span><a id="line.539">     *   &lt;li&gt;</a>
<span class="sourceLineNo">540</span><a id="line.540">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">541</span><a id="line.541">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">542</span><a id="line.542">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">543</span><a id="line.543">     *   &lt;li&gt;</a>
<span class="sourceLineNo">544</span><a id="line.544">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">545</span><a id="line.545">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">546</span><a id="line.546">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">547</span><a id="line.547">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">548</span><a id="line.548">     */</a>
<span class="sourceLineNo">549</span><a id="line.549">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel, TermCriteria criteria) {</a>
<span class="sourceLineNo">550</span><a id="line.550">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">551</span><a id="line.551">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">552</span><a id="line.552">        Mat status_mat = status;</a>
<span class="sourceLineNo">553</span><a id="line.553">        Mat err_mat = err;</a>
<span class="sourceLineNo">554</span><a id="line.554">        calcOpticalFlowPyrLK_2(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel, criteria.type, criteria.maxCount, criteria.epsilon);</a>
<span class="sourceLineNo">555</span><a id="line.555">    }</a>
<span class="sourceLineNo">556</span><a id="line.556"></a>
<span class="sourceLineNo">557</span><a id="line.557">    /**</a>
<span class="sourceLineNo">558</span><a id="line.558">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">559</span><a id="line.559">     * pyramids.</a>
<span class="sourceLineNo">560</span><a id="line.560">     *</a>
<span class="sourceLineNo">561</span><a id="line.561">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">562</span><a id="line.562">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">563</span><a id="line.563">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">564</span><a id="line.564">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">565</span><a id="line.565">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">566</span><a id="line.566">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">567</span><a id="line.567">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">568</span><a id="line.568">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">569</span><a id="line.569">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">570</span><a id="line.570">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">571</span><a id="line.571">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">572</span><a id="line.572">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">573</span><a id="line.573">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">574</span><a id="line.574">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">575</span><a id="line.575">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">576</span><a id="line.576">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">577</span><a id="line.577">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">578</span><a id="line.578">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">579</span><a id="line.579">     * &lt;ul&gt;</a>
<span class="sourceLineNo">580</span><a id="line.580">     *   &lt;li&gt;</a>
<span class="sourceLineNo">581</span><a id="line.581">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">582</span><a id="line.582">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">583</span><a id="line.583">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">584</span><a id="line.584">     *   &lt;li&gt;</a>
<span class="sourceLineNo">585</span><a id="line.585">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">586</span><a id="line.586">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">587</span><a id="line.587">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">588</span><a id="line.588">     *      error measure.</a>
<span class="sourceLineNo">589</span><a id="line.589">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">590</span><a id="line.590">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">591</span><a id="line.591">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">592</span><a id="line.592">     * performance boost.</a>
<span class="sourceLineNo">593</span><a id="line.593">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">594</span><a id="line.594">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">595</span><a id="line.595">     *</a>
<span class="sourceLineNo">596</span><a id="line.596">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">597</span><a id="line.597">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">598</span><a id="line.598">     *</a>
<span class="sourceLineNo">599</span><a id="line.599">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">600</span><a id="line.600">     *</a>
<span class="sourceLineNo">601</span><a id="line.601">     * &lt;ul&gt;</a>
<span class="sourceLineNo">602</span><a id="line.602">     *   &lt;li&gt;</a>
<span class="sourceLineNo">603</span><a id="line.603">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">604</span><a id="line.604">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">605</span><a id="line.605">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">606</span><a id="line.606">     *   &lt;li&gt;</a>
<span class="sourceLineNo">607</span><a id="line.607">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">608</span><a id="line.608">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">609</span><a id="line.609">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">610</span><a id="line.610">     *   &lt;li&gt;</a>
<span class="sourceLineNo">611</span><a id="line.611">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">612</span><a id="line.612">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">613</span><a id="line.613">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">614</span><a id="line.614">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">615</span><a id="line.615">     */</a>
<span class="sourceLineNo">616</span><a id="line.616">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel) {</a>
<span class="sourceLineNo">617</span><a id="line.617">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">618</span><a id="line.618">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">619</span><a id="line.619">        Mat status_mat = status;</a>
<span class="sourceLineNo">620</span><a id="line.620">        Mat err_mat = err;</a>
<span class="sourceLineNo">621</span><a id="line.621">        calcOpticalFlowPyrLK_3(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel);</a>
<span class="sourceLineNo">622</span><a id="line.622">    }</a>
<span class="sourceLineNo">623</span><a id="line.623"></a>
<span class="sourceLineNo">624</span><a id="line.624">    /**</a>
<span class="sourceLineNo">625</span><a id="line.625">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">626</span><a id="line.626">     * pyramids.</a>
<span class="sourceLineNo">627</span><a id="line.627">     *</a>
<span class="sourceLineNo">628</span><a id="line.628">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">629</span><a id="line.629">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">630</span><a id="line.630">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">631</span><a id="line.631">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">632</span><a id="line.632">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">633</span><a id="line.633">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">634</span><a id="line.634">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">635</span><a id="line.635">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">636</span><a id="line.636">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">637</span><a id="line.637">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">638</span><a id="line.638">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">639</span><a id="line.639">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">640</span><a id="line.640">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">641</span><a id="line.641">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">642</span><a id="line.642">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">643</span><a id="line.643">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">644</span><a id="line.644">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">645</span><a id="line.645">     * &lt;ul&gt;</a>
<span class="sourceLineNo">646</span><a id="line.646">     *   &lt;li&gt;</a>
<span class="sourceLineNo">647</span><a id="line.647">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">648</span><a id="line.648">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">649</span><a id="line.649">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">650</span><a id="line.650">     *   &lt;li&gt;</a>
<span class="sourceLineNo">651</span><a id="line.651">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">652</span><a id="line.652">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">653</span><a id="line.653">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">654</span><a id="line.654">     *      error measure.</a>
<span class="sourceLineNo">655</span><a id="line.655">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">656</span><a id="line.656">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">657</span><a id="line.657">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">658</span><a id="line.658">     * performance boost.</a>
<span class="sourceLineNo">659</span><a id="line.659">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">660</span><a id="line.660">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">661</span><a id="line.661">     *</a>
<span class="sourceLineNo">662</span><a id="line.662">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">663</span><a id="line.663">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">664</span><a id="line.664">     *</a>
<span class="sourceLineNo">665</span><a id="line.665">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">666</span><a id="line.666">     *</a>
<span class="sourceLineNo">667</span><a id="line.667">     * &lt;ul&gt;</a>
<span class="sourceLineNo">668</span><a id="line.668">     *   &lt;li&gt;</a>
<span class="sourceLineNo">669</span><a id="line.669">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">670</span><a id="line.670">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">671</span><a id="line.671">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">672</span><a id="line.672">     *   &lt;li&gt;</a>
<span class="sourceLineNo">673</span><a id="line.673">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">674</span><a id="line.674">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">675</span><a id="line.675">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">676</span><a id="line.676">     *   &lt;li&gt;</a>
<span class="sourceLineNo">677</span><a id="line.677">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">678</span><a id="line.678">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">679</span><a id="line.679">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">680</span><a id="line.680">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">681</span><a id="line.681">     */</a>
<span class="sourceLineNo">682</span><a id="line.682">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize) {</a>
<span class="sourceLineNo">683</span><a id="line.683">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">684</span><a id="line.684">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">685</span><a id="line.685">        Mat status_mat = status;</a>
<span class="sourceLineNo">686</span><a id="line.686">        Mat err_mat = err;</a>
<span class="sourceLineNo">687</span><a id="line.687">        calcOpticalFlowPyrLK_4(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height);</a>
<span class="sourceLineNo">688</span><a id="line.688">    }</a>
<span class="sourceLineNo">689</span><a id="line.689"></a>
<span class="sourceLineNo">690</span><a id="line.690">    /**</a>
<span class="sourceLineNo">691</span><a id="line.691">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">692</span><a id="line.692">     * pyramids.</a>
<span class="sourceLineNo">693</span><a id="line.693">     *</a>
<span class="sourceLineNo">694</span><a id="line.694">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">695</span><a id="line.695">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">696</span><a id="line.696">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">697</span><a id="line.697">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">698</span><a id="line.698">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">699</span><a id="line.699">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">700</span><a id="line.700">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">701</span><a id="line.701">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">702</span><a id="line.702">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">703</span><a id="line.703">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">704</span><a id="line.704">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">705</span><a id="line.705">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">706</span><a id="line.706">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">707</span><a id="line.707">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">708</span><a id="line.708">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">709</span><a id="line.709">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">710</span><a id="line.710">     * &lt;ul&gt;</a>
<span class="sourceLineNo">711</span><a id="line.711">     *   &lt;li&gt;</a>
<span class="sourceLineNo">712</span><a id="line.712">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">713</span><a id="line.713">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">714</span><a id="line.714">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">715</span><a id="line.715">     *   &lt;li&gt;</a>
<span class="sourceLineNo">716</span><a id="line.716">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">717</span><a id="line.717">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">718</span><a id="line.718">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">719</span><a id="line.719">     *      error measure.</a>
<span class="sourceLineNo">720</span><a id="line.720">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">721</span><a id="line.721">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">722</span><a id="line.722">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">723</span><a id="line.723">     * performance boost.</a>
<span class="sourceLineNo">724</span><a id="line.724">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">725</span><a id="line.725">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">726</span><a id="line.726">     *</a>
<span class="sourceLineNo">727</span><a id="line.727">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">728</span><a id="line.728">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">729</span><a id="line.729">     *</a>
<span class="sourceLineNo">730</span><a id="line.730">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">731</span><a id="line.731">     *</a>
<span class="sourceLineNo">732</span><a id="line.732">     * &lt;ul&gt;</a>
<span class="sourceLineNo">733</span><a id="line.733">     *   &lt;li&gt;</a>
<span class="sourceLineNo">734</span><a id="line.734">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">735</span><a id="line.735">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">736</span><a id="line.736">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">737</span><a id="line.737">     *   &lt;li&gt;</a>
<span class="sourceLineNo">738</span><a id="line.738">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">739</span><a id="line.739">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">740</span><a id="line.740">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">741</span><a id="line.741">     *   &lt;li&gt;</a>
<span class="sourceLineNo">742</span><a id="line.742">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">743</span><a id="line.743">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">744</span><a id="line.744">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">745</span><a id="line.745">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">746</span><a id="line.746">     */</a>
<span class="sourceLineNo">747</span><a id="line.747">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err) {</a>
<span class="sourceLineNo">748</span><a id="line.748">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">749</span><a id="line.749">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">750</span><a id="line.750">        Mat status_mat = status;</a>
<span class="sourceLineNo">751</span><a id="line.751">        Mat err_mat = err;</a>
<span class="sourceLineNo">752</span><a id="line.752">        calcOpticalFlowPyrLK_5(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj);</a>
<span class="sourceLineNo">753</span><a id="line.753">    }</a>
<span class="sourceLineNo">754</span><a id="line.754"></a>
<span class="sourceLineNo">755</span><a id="line.755"></a>
<span class="sourceLineNo">756</span><a id="line.756">    //</a>
<span class="sourceLineNo">757</span><a id="line.757">    // C++:  void cv::calcOpticalFlowFarneback(Mat prev, Mat next, Mat&amp; flow, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags)</a>
<span class="sourceLineNo">758</span><a id="line.758">    //</a>
<span class="sourceLineNo">759</span><a id="line.759"></a>
<span class="sourceLineNo">760</span><a id="line.760">    /**</a>
<span class="sourceLineNo">761</span><a id="line.761">     * Computes a dense optical flow using the Gunnar Farneback's algorithm.</a>
<span class="sourceLineNo">762</span><a id="line.762">     *</a>
<span class="sourceLineNo">763</span><a id="line.763">     * @param prev first 8-bit single-channel input image.</a>
<span class="sourceLineNo">764</span><a id="line.764">     * @param next second input image of the same size and the same type as prev.</a>
<span class="sourceLineNo">765</span><a id="line.765">     * @param flow computed flow image that has the same size as prev and type CV_32FC2.</a>
<span class="sourceLineNo">766</span><a id="line.766">     * @param pyr_scale parameter, specifying the image scale (&amp;lt;1) to build pyramids for each image;</a>
<span class="sourceLineNo">767</span><a id="line.767">     * pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous</a>
<span class="sourceLineNo">768</span><a id="line.768">     * one.</a>
<span class="sourceLineNo">769</span><a id="line.769">     * @param levels number of pyramid layers including the initial image; levels=1 means that no extra</a>
<span class="sourceLineNo">770</span><a id="line.770">     * layers are created and only the original images are used.</a>
<span class="sourceLineNo">771</span><a id="line.771">     * @param winsize averaging window size; larger values increase the algorithm robustness to image</a>
<span class="sourceLineNo">772</span><a id="line.772">     * noise and give more chances for fast motion detection, but yield more blurred motion field.</a>
<span class="sourceLineNo">773</span><a id="line.773">     * @param iterations number of iterations the algorithm does at each pyramid level.</a>
<span class="sourceLineNo">774</span><a id="line.774">     * @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;</a>
<span class="sourceLineNo">775</span><a id="line.775">     * larger values mean that the image will be approximated with smoother surfaces, yielding more</a>
<span class="sourceLineNo">776</span><a id="line.776">     * robust algorithm and more blurred motion field, typically poly_n =5 or 7.</a>
<span class="sourceLineNo">777</span><a id="line.777">     * @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a</a>
<span class="sourceLineNo">778</span><a id="line.778">     * basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a</a>
<span class="sourceLineNo">779</span><a id="line.779">     * good value would be poly_sigma=1.5.</a>
<span class="sourceLineNo">780</span><a id="line.780">     * @param flags operation flags that can be a combination of the following:</a>
<span class="sourceLineNo">781</span><a id="line.781">     * &lt;ul&gt;</a>
<span class="sourceLineNo">782</span><a id="line.782">     *   &lt;li&gt;</a>
<span class="sourceLineNo">783</span><a id="line.783">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses the input flow as an initial flow approximation.</a>
<span class="sourceLineNo">784</span><a id="line.784">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">785</span><a id="line.785">     *   &lt;li&gt;</a>
<span class="sourceLineNo">786</span><a id="line.786">     *     &lt;b&gt;OPTFLOW_FARNEBACK_GAUSSIAN&lt;/b&gt; uses the Gaussian \(\texttt{winsize}\times\texttt{winsize}\)</a>
<span class="sourceLineNo">787</span><a id="line.787">     *      filter instead of a box filter of the same size for optical flow estimation; usually, this</a>
<span class="sourceLineNo">788</span><a id="line.788">     *      option gives z more accurate flow than with a box filter, at the cost of lower speed;</a>
<span class="sourceLineNo">789</span><a id="line.789">     *      normally, winsize for a Gaussian window should be set to a larger value to achieve the same</a>
<span class="sourceLineNo">790</span><a id="line.790">     *      level of robustness.</a>
<span class="sourceLineNo">791</span><a id="line.791">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">792</span><a id="line.792">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">793</span><a id="line.793">     *</a>
<span class="sourceLineNo">794</span><a id="line.794">     * The function finds an optical flow for each prev pixel using the CITE: Farneback2003 algorithm so that</a>
<span class="sourceLineNo">795</span><a id="line.795">     *</a>
<span class="sourceLineNo">796</span><a id="line.796">     * \(\texttt{prev} (y,x)  \sim \texttt{next} ( y + \texttt{flow} (y,x)[1],  x + \texttt{flow} (y,x)[0])\)</a>
<span class="sourceLineNo">797</span><a id="line.797">     *</a>
<span class="sourceLineNo">798</span><a id="line.798">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">799</span><a id="line.799">     *</a>
<span class="sourceLineNo">800</span><a id="line.800">     * &lt;ul&gt;</a>
<span class="sourceLineNo">801</span><a id="line.801">     *   &lt;li&gt;</a>
<span class="sourceLineNo">802</span><a id="line.802">     *    An example using the optical flow algorithm described by Gunnar Farneback can be found at</a>
<span class="sourceLineNo">803</span><a id="line.803">     *     opencv_source_code/samples/cpp/fback.cpp</a>
<span class="sourceLineNo">804</span><a id="line.804">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">805</span><a id="line.805">     *   &lt;li&gt;</a>
<span class="sourceLineNo">806</span><a id="line.806">     *    (Python) An example using the optical flow algorithm described by Gunnar Farneback can be</a>
<span class="sourceLineNo">807</span><a id="line.807">     *     found at opencv_source_code/samples/python/opt_flow.py</a>
<span class="sourceLineNo">808</span><a id="line.808">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">809</span><a id="line.809">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">810</span><a id="line.810">     */</a>
<span class="sourceLineNo">811</span><a id="line.811">    public static void calcOpticalFlowFarneback(Mat prev, Mat next, Mat flow, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags) {</a>
<span class="sourceLineNo">812</span><a id="line.812">        calcOpticalFlowFarneback_0(prev.nativeObj, next.nativeObj, flow.nativeObj, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags);</a>
<span class="sourceLineNo">813</span><a id="line.813">    }</a>
<span class="sourceLineNo">814</span><a id="line.814"></a>
<span class="sourceLineNo">815</span><a id="line.815"></a>
<span class="sourceLineNo">816</span><a id="line.816">    //</a>
<span class="sourceLineNo">817</span><a id="line.817">    // C++:  double cv::computeECC(Mat templateImage, Mat inputImage, Mat inputMask = Mat())</a>
<span class="sourceLineNo">818</span><a id="line.818">    //</a>
<span class="sourceLineNo">819</span><a id="line.819"></a>
<span class="sourceLineNo">820</span><a id="line.820">    /**</a>
<span class="sourceLineNo">821</span><a id="line.821">     * Computes the Enhanced Correlation Coefficient value between two images CITE: EP08 .</a>
<span class="sourceLineNo">822</span><a id="line.822">     *</a>
<span class="sourceLineNo">823</span><a id="line.823">     * @param templateImage single-channel template image; CV_8U or CV_32F array.</a>
<span class="sourceLineNo">824</span><a id="line.824">     * @param inputImage single-channel input image to be warped to provide an image similar to</a>
<span class="sourceLineNo">825</span><a id="line.825">     *  templateImage, same type as templateImage.</a>
<span class="sourceLineNo">826</span><a id="line.826">     * @param inputMask An optional mask to indicate valid values of inputImage.</a>
<span class="sourceLineNo">827</span><a id="line.827">     *</a>
<span class="sourceLineNo">828</span><a id="line.828">     * SEE:</a>
<span class="sourceLineNo">829</span><a id="line.829">     * findTransformECC</a>
<span class="sourceLineNo">830</span><a id="line.830">     * @return automatically generated</a>
<span class="sourceLineNo">831</span><a id="line.831">     */</a>
<span class="sourceLineNo">832</span><a id="line.832">    public static double computeECC(Mat templateImage, Mat inputImage, Mat inputMask) {</a>
<span class="sourceLineNo">833</span><a id="line.833">        return computeECC_0(templateImage.nativeObj, inputImage.nativeObj, inputMask.nativeObj);</a>
<span class="sourceLineNo">834</span><a id="line.834">    }</a>
<span class="sourceLineNo">835</span><a id="line.835"></a>
<span class="sourceLineNo">836</span><a id="line.836">    /**</a>
<span class="sourceLineNo">837</span><a id="line.837">     * Computes the Enhanced Correlation Coefficient value between two images CITE: EP08 .</a>
<span class="sourceLineNo">838</span><a id="line.838">     *</a>
<span class="sourceLineNo">839</span><a id="line.839">     * @param templateImage single-channel template image; CV_8U or CV_32F array.</a>
<span class="sourceLineNo">840</span><a id="line.840">     * @param inputImage single-channel input image to be warped to provide an image similar to</a>
<span class="sourceLineNo">841</span><a id="line.841">     *  templateImage, same type as templateImage.</a>
<span class="sourceLineNo">842</span><a id="line.842">     *</a>
<span class="sourceLineNo">843</span><a id="line.843">     * SEE:</a>
<span class="sourceLineNo">844</span><a id="line.844">     * findTransformECC</a>
<span class="sourceLineNo">845</span><a id="line.845">     * @return automatically generated</a>
<span class="sourceLineNo">846</span><a id="line.846">     */</a>
<span class="sourceLineNo">847</span><a id="line.847">    public static double computeECC(Mat templateImage, Mat inputImage) {</a>
<span class="sourceLineNo">848</span><a id="line.848">        return computeECC_1(templateImage.nativeObj, inputImage.nativeObj);</a>
<span class="sourceLineNo">849</span><a id="line.849">    }</a>
<span class="sourceLineNo">850</span><a id="line.850"></a>
<span class="sourceLineNo">851</span><a id="line.851"></a>
<span class="sourceLineNo">852</span><a id="line.852">    //</a>
<span class="sourceLineNo">853</span><a id="line.853">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize)</a>
<span class="sourceLineNo">854</span><a id="line.854">    //</a>
<span class="sourceLineNo">855</span><a id="line.855"></a>
<span class="sourceLineNo">856</span><a id="line.856">    /**</a>
<span class="sourceLineNo">857</span><a id="line.857">     * Finds the geometric transform (warp) between two images in terms of the ECC criterion CITE: EP08 .</a>
<span class="sourceLineNo">858</span><a id="line.858">     *</a>
<span class="sourceLineNo">859</span><a id="line.859">     * @param templateImage single-channel template image; CV_8U or CV_32F array.</a>
<span class="sourceLineNo">860</span><a id="line.860">     * @param inputImage single-channel input image which should be warped with the final warpMatrix in</a>
<span class="sourceLineNo">861</span><a id="line.861">     * order to provide an image similar to templateImage, same type as templateImage.</a>
<span class="sourceLineNo">862</span><a id="line.862">     * @param warpMatrix floating-point \(2\times 3\) or \(3\times 3\) mapping matrix (warp).</a>
<span class="sourceLineNo">863</span><a id="line.863">     * @param motionType parameter, specifying the type of motion:</a>
<span class="sourceLineNo">864</span><a id="line.864">     * &lt;ul&gt;</a>
<span class="sourceLineNo">865</span><a id="line.865">     *   &lt;li&gt;</a>
<span class="sourceLineNo">866</span><a id="line.866">     *     &lt;b&gt;MOTION_TRANSLATION&lt;/b&gt; sets a translational motion model; warpMatrix is \(2\times 3\) with</a>
<span class="sourceLineNo">867</span><a id="line.867">     *      the first \(2\times 2\) part being the unity matrix and the rest two parameters being</a>
<span class="sourceLineNo">868</span><a id="line.868">     *      estimated.</a>
<span class="sourceLineNo">869</span><a id="line.869">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">870</span><a id="line.870">     *   &lt;li&gt;</a>
<span class="sourceLineNo">871</span><a id="line.871">     *     &lt;b&gt;MOTION_EUCLIDEAN&lt;/b&gt; sets a Euclidean (rigid) transformation as motion model; three</a>
<span class="sourceLineNo">872</span><a id="line.872">     *      parameters are estimated; warpMatrix is \(2\times 3\).</a>
<span class="sourceLineNo">873</span><a id="line.873">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">874</span><a id="line.874">     *   &lt;li&gt;</a>
<span class="sourceLineNo">875</span><a id="line.875">     *     &lt;b&gt;MOTION_AFFINE&lt;/b&gt; sets an affine motion model (DEFAULT); six parameters are estimated;</a>
<span class="sourceLineNo">876</span><a id="line.876">     *      warpMatrix is \(2\times 3\).</a>
<span class="sourceLineNo">877</span><a id="line.877">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">878</span><a id="line.878">     *   &lt;li&gt;</a>
<span class="sourceLineNo">879</span><a id="line.879">     *     &lt;b&gt;MOTION_HOMOGRAPHY&lt;/b&gt; sets a homography as a motion model; eight parameters are</a>
<span class="sourceLineNo">880</span><a id="line.880">     *      estimated;\{@code warpMatrix\} is \(3\times 3\).</a>
<span class="sourceLineNo">881</span><a id="line.881">     * @param criteria parameter, specifying the termination criteria of the ECC algorithm;</a>
<span class="sourceLineNo">882</span><a id="line.882">     * criteria.epsilon defines the threshold of the increment in the correlation coefficient between two</a>
<span class="sourceLineNo">883</span><a id="line.883">     * iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion).</a>
<span class="sourceLineNo">884</span><a id="line.884">     * Default values are shown in the declaration above.</a>
<span class="sourceLineNo">885</span><a id="line.885">     * @param inputMask An optional mask to indicate valid values of inputImage.</a>
<span class="sourceLineNo">886</span><a id="line.886">     * @param gaussFiltSize An optional value indicating size of gaussian blur filter; (DEFAULT: 5)</a>
<span class="sourceLineNo">887</span><a id="line.887">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">888</span><a id="line.888">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">889</span><a id="line.889">     *</a>
<span class="sourceLineNo">890</span><a id="line.890">     * The function estimates the optimum transformation (warpMatrix) with respect to ECC criterion</a>
<span class="sourceLineNo">891</span><a id="line.891">     * (CITE: EP08), that is</a>
<span class="sourceLineNo">892</span><a id="line.892">     *</a>
<span class="sourceLineNo">893</span><a id="line.893">     * \(\texttt{warpMatrix} = \arg\max_{W} \texttt{ECC}(\texttt{templateImage}(x,y),\texttt{inputImage}(x',y'))\)</a>
<span class="sourceLineNo">894</span><a id="line.894">     *</a>
<span class="sourceLineNo">895</span><a id="line.895">     * where</a>
<span class="sourceLineNo">896</span><a id="line.896">     *</a>
<span class="sourceLineNo">897</span><a id="line.897">     * \(\begin{bmatrix} x' \\ y' \end{bmatrix} = W \cdot \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}\)</a>
<span class="sourceLineNo">898</span><a id="line.898">     *</a>
<span class="sourceLineNo">899</span><a id="line.899">     * (the equation holds with homogeneous coordinates for homography). It returns the final enhanced</a>
<span class="sourceLineNo">900</span><a id="line.900">     * correlation coefficient, that is the correlation coefficient between the template image and the</a>
<span class="sourceLineNo">901</span><a id="line.901">     * final warped input image. When a \(3\times 3\) matrix is given with motionType =0, 1 or 2, the third</a>
<span class="sourceLineNo">902</span><a id="line.902">     * row is ignored.</a>
<span class="sourceLineNo">903</span><a id="line.903">     *</a>
<span class="sourceLineNo">904</span><a id="line.904">     * Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an</a>
<span class="sourceLineNo">905</span><a id="line.905">     * area-based alignment that builds on intensity similarities. In essence, the function updates the</a>
<span class="sourceLineNo">906</span><a id="line.906">     * initial transformation that roughly aligns the images. If this information is missing, the identity</a>
<span class="sourceLineNo">907</span><a id="line.907">     * warp (unity matrix) is used as an initialization. Note that if images undergo strong</a>
<span class="sourceLineNo">908</span><a id="line.908">     * displacements/rotations, an initial transformation that roughly aligns the images is necessary</a>
<span class="sourceLineNo">909</span><a id="line.909">     * (e.g., a simple euclidean/similarity transform that allows for the images showing the same image</a>
<span class="sourceLineNo">910</span><a id="line.910">     * content approximately). Use inverse warping in the second image to take an image close to the first</a>
<span class="sourceLineNo">911</span><a id="line.911">     * one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV</a>
<span class="sourceLineNo">912</span><a id="line.912">     * sample image_alignment.cpp that demonstrates the use of the function. Note that the function throws</a>
<span class="sourceLineNo">913</span><a id="line.913">     * an exception if algorithm does not converges.</a>
<span class="sourceLineNo">914</span><a id="line.914">     *</a>
<span class="sourceLineNo">915</span><a id="line.915">     * SEE:</a>
<span class="sourceLineNo">916</span><a id="line.916">     * computeECC, estimateAffine2D, estimateAffinePartial2D, findHomography</a>
<span class="sourceLineNo">917</span><a id="line.917">     * @return automatically generated</a>
<span class="sourceLineNo">918</span><a id="line.918">     */</a>
<span class="sourceLineNo">919</span><a id="line.919">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize) {</a>
<span class="sourceLineNo">920</span><a id="line.920">        return findTransformECC_0(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType, criteria.type, criteria.maxCount, criteria.epsilon, inputMask.nativeObj, gaussFiltSize);</a>
<span class="sourceLineNo">921</span><a id="line.921">    }</a>
<span class="sourceLineNo">922</span><a id="line.922"></a>
<span class="sourceLineNo">923</span><a id="line.923"></a>
<span class="sourceLineNo">924</span><a id="line.924">    //</a>
<span class="sourceLineNo">925</span><a id="line.925">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType = MOTION_AFFINE, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 50, 0.001), Mat inputMask = Mat())</a>
<span class="sourceLineNo">926</span><a id="line.926">    //</a>
<span class="sourceLineNo">927</span><a id="line.927"></a>
<span class="sourceLineNo">928</span><a id="line.928">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria, Mat inputMask) {</a>
<span class="sourceLineNo">929</span><a id="line.929">        return findTransformECC_1(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType, criteria.type, criteria.maxCount, criteria.epsilon, inputMask.nativeObj);</a>
<span class="sourceLineNo">930</span><a id="line.930">    }</a>
<span class="sourceLineNo">931</span><a id="line.931"></a>
<span class="sourceLineNo">932</span><a id="line.932">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria) {</a>
<span class="sourceLineNo">933</span><a id="line.933">        return findTransformECC_2(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType, criteria.type, criteria.maxCount, criteria.epsilon);</a>
<span class="sourceLineNo">934</span><a id="line.934">    }</a>
<span class="sourceLineNo">935</span><a id="line.935"></a>
<span class="sourceLineNo">936</span><a id="line.936">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType) {</a>
<span class="sourceLineNo">937</span><a id="line.937">        return findTransformECC_3(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType);</a>
<span class="sourceLineNo">938</span><a id="line.938">    }</a>
<span class="sourceLineNo">939</span><a id="line.939"></a>
<span class="sourceLineNo">940</span><a id="line.940">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix) {</a>
<span class="sourceLineNo">941</span><a id="line.941">        return findTransformECC_4(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj);</a>
<span class="sourceLineNo">942</span><a id="line.942">    }</a>
<span class="sourceLineNo">943</span><a id="line.943"></a>
<span class="sourceLineNo">944</span><a id="line.944"></a>
<span class="sourceLineNo">945</span><a id="line.945">    //</a>
<span class="sourceLineNo">946</span><a id="line.946">    // C++:  Mat cv::readOpticalFlow(String path)</a>
<span class="sourceLineNo">947</span><a id="line.947">    //</a>
<span class="sourceLineNo">948</span><a id="line.948"></a>
<span class="sourceLineNo">949</span><a id="line.949">    /**</a>
<span class="sourceLineNo">950</span><a id="line.950">     * Read a .flo file</a>
<span class="sourceLineNo">951</span><a id="line.951">     *</a>
<span class="sourceLineNo">952</span><a id="line.952">     *  @param path Path to the file to be loaded</a>
<span class="sourceLineNo">953</span><a id="line.953">     *</a>
<span class="sourceLineNo">954</span><a id="line.954">     *  The function readOpticalFlow loads a flow field from a file and returns it as a single matrix.</a>
<span class="sourceLineNo">955</span><a id="line.955">     *  Resulting Mat has a type CV_32FC2 - floating-point, 2-channel. First channel corresponds to the</a>
<span class="sourceLineNo">956</span><a id="line.956">     *  flow in the horizontal direction (u), second - vertical (v).</a>
<span class="sourceLineNo">957</span><a id="line.957">     * @return automatically generated</a>
<span class="sourceLineNo">958</span><a id="line.958">     */</a>
<span class="sourceLineNo">959</span><a id="line.959">    public static Mat readOpticalFlow(String path) {</a>
<span class="sourceLineNo">960</span><a id="line.960">        return new Mat(readOpticalFlow_0(path));</a>
<span class="sourceLineNo">961</span><a id="line.961">    }</a>
<span class="sourceLineNo">962</span><a id="line.962"></a>
<span class="sourceLineNo">963</span><a id="line.963"></a>
<span class="sourceLineNo">964</span><a id="line.964">    //</a>
<span class="sourceLineNo">965</span><a id="line.965">    // C++:  bool cv::writeOpticalFlow(String path, Mat flow)</a>
<span class="sourceLineNo">966</span><a id="line.966">    //</a>
<span class="sourceLineNo">967</span><a id="line.967"></a>
<span class="sourceLineNo">968</span><a id="line.968">    /**</a>
<span class="sourceLineNo">969</span><a id="line.969">     * Write a .flo to disk</a>
<span class="sourceLineNo">970</span><a id="line.970">     *</a>
<span class="sourceLineNo">971</span><a id="line.971">     *  @param path Path to the file to be written</a>
<span class="sourceLineNo">972</span><a id="line.972">     *  @param flow Flow field to be stored</a>
<span class="sourceLineNo">973</span><a id="line.973">     *</a>
<span class="sourceLineNo">974</span><a id="line.974">     *  The function stores a flow field in a file, returns true on success, false otherwise.</a>
<span class="sourceLineNo">975</span><a id="line.975">     *  The flow field must be a 2-channel, floating-point matrix (CV_32FC2). First channel corresponds</a>
<span class="sourceLineNo">976</span><a id="line.976">     *  to the flow in the horizontal direction (u), second - vertical (v).</a>
<span class="sourceLineNo">977</span><a id="line.977">     * @return automatically generated</a>
<span class="sourceLineNo">978</span><a id="line.978">     */</a>
<span class="sourceLineNo">979</span><a id="line.979">    public static boolean writeOpticalFlow(String path, Mat flow) {</a>
<span class="sourceLineNo">980</span><a id="line.980">        return writeOpticalFlow_0(path, flow.nativeObj);</a>
<span class="sourceLineNo">981</span><a id="line.981">    }</a>
<span class="sourceLineNo">982</span><a id="line.982"></a>
<span class="sourceLineNo">983</span><a id="line.983"></a>
<span class="sourceLineNo">984</span><a id="line.984"></a>
<span class="sourceLineNo">985</span><a id="line.985"></a>
<span class="sourceLineNo">986</span><a id="line.986">    // C++:  Ptr_BackgroundSubtractorMOG2 cv::createBackgroundSubtractorMOG2(int history = 500, double varThreshold = 16, bool detectShadows = true)</a>
<span class="sourceLineNo">987</span><a id="line.987">    private static native long createBackgroundSubtractorMOG2_0(int history, double varThreshold, boolean detectShadows);</a>
<span class="sourceLineNo">988</span><a id="line.988">    private static native long createBackgroundSubtractorMOG2_1(int history, double varThreshold);</a>
<span class="sourceLineNo">989</span><a id="line.989">    private static native long createBackgroundSubtractorMOG2_2(int history);</a>
<span class="sourceLineNo">990</span><a id="line.990">    private static native long createBackgroundSubtractorMOG2_3();</a>
<span class="sourceLineNo">991</span><a id="line.991"></a>
<span class="sourceLineNo">992</span><a id="line.992">    // C++:  Ptr_BackgroundSubtractorKNN cv::createBackgroundSubtractorKNN(int history = 500, double dist2Threshold = 400.0, bool detectShadows = true)</a>
<span class="sourceLineNo">993</span><a id="line.993">    private static native long createBackgroundSubtractorKNN_0(int history, double dist2Threshold, boolean detectShadows);</a>
<span class="sourceLineNo">994</span><a id="line.994">    private static native long createBackgroundSubtractorKNN_1(int history, double dist2Threshold);</a>
<span class="sourceLineNo">995</span><a id="line.995">    private static native long createBackgroundSubtractorKNN_2(int history);</a>
<span class="sourceLineNo">996</span><a id="line.996">    private static native long createBackgroundSubtractorKNN_3();</a>
<span class="sourceLineNo">997</span><a id="line.997"></a>
<span class="sourceLineNo">998</span><a id="line.998">    // C++:  RotatedRect cv::CamShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">999</span><a id="line.999">    private static native double[] CamShift_0(long probImage_nativeObj, int window_x, int window_y, int window_width, int window_height, double[] window_out, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">1000</span><a id="line.1000"></a>
<span class="sourceLineNo">1001</span><a id="line.1001">    // C++:  int cv::meanShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">1002</span><a id="line.1002">    private static native int meanShift_0(long probImage_nativeObj, int window_x, int window_y, int window_width, int window_height, double[] window_out, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">1003</span><a id="line.1003"></a>
<span class="sourceLineNo">1004</span><a id="line.1004">    // C++:  int cv::buildOpticalFlowPyramid(Mat img, vector_Mat&amp; pyramid, Size winSize, int maxLevel, bool withDerivatives = true, int pyrBorder = BORDER_REFLECT_101, int derivBorder = BORDER_CONSTANT, bool tryReuseInputImage = true)</a>
<span class="sourceLineNo">1005</span><a id="line.1005">    private static native int buildOpticalFlowPyramid_0(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder, boolean tryReuseInputImage);</a>
<span class="sourceLineNo">1006</span><a id="line.1006">    private static native int buildOpticalFlowPyramid_1(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder);</a>
<span class="sourceLineNo">1007</span><a id="line.1007">    private static native int buildOpticalFlowPyramid_2(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives, int pyrBorder);</a>
<span class="sourceLineNo">1008</span><a id="line.1008">    private static native int buildOpticalFlowPyramid_3(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives);</a>
<span class="sourceLineNo">1009</span><a id="line.1009">    private static native int buildOpticalFlowPyramid_4(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel);</a>
<span class="sourceLineNo">1010</span><a id="line.1010"></a>
<span class="sourceLineNo">1011</span><a id="line.1011">    // C++:  void cv::calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, vector_Point2f prevPts, vector_Point2f&amp; nextPts, vector_uchar&amp; status, vector_float&amp; err, Size winSize = Size(21,21), int maxLevel = 3, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01), int flags = 0, double minEigThreshold = 1e-4)</a>
<span class="sourceLineNo">1012</span><a id="line.1012">    private static native void calcOpticalFlowPyrLK_0(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, int criteria_type, int criteria_maxCount, double criteria_epsilon, int flags, double minEigThreshold);</a>
<span class="sourceLineNo">1013</span><a id="line.1013">    private static native void calcOpticalFlowPyrLK_1(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, int criteria_type, int criteria_maxCount, double criteria_epsilon, int flags);</a>
<span class="sourceLineNo">1014</span><a id="line.1014">    private static native void calcOpticalFlowPyrLK_2(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">1015</span><a id="line.1015">    private static native void calcOpticalFlowPyrLK_3(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel);</a>
<span class="sourceLineNo">1016</span><a id="line.1016">    private static native void calcOpticalFlowPyrLK_4(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height);</a>
<span class="sourceLineNo">1017</span><a id="line.1017">    private static native void calcOpticalFlowPyrLK_5(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj);</a>
<span class="sourceLineNo">1018</span><a id="line.1018"></a>
<span class="sourceLineNo">1019</span><a id="line.1019">    // C++:  void cv::calcOpticalFlowFarneback(Mat prev, Mat next, Mat&amp; flow, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags)</a>
<span class="sourceLineNo">1020</span><a id="line.1020">    private static native void calcOpticalFlowFarneback_0(long prev_nativeObj, long next_nativeObj, long flow_nativeObj, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags);</a>
<span class="sourceLineNo">1021</span><a id="line.1021"></a>
<span class="sourceLineNo">1022</span><a id="line.1022">    // C++:  double cv::computeECC(Mat templateImage, Mat inputImage, Mat inputMask = Mat())</a>
<span class="sourceLineNo">1023</span><a id="line.1023">    private static native double computeECC_0(long templateImage_nativeObj, long inputImage_nativeObj, long inputMask_nativeObj);</a>
<span class="sourceLineNo">1024</span><a id="line.1024">    private static native double computeECC_1(long templateImage_nativeObj, long inputImage_nativeObj);</a>
<span class="sourceLineNo">1025</span><a id="line.1025"></a>
<span class="sourceLineNo">1026</span><a id="line.1026">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize)</a>
<span class="sourceLineNo">1027</span><a id="line.1027">    private static native double findTransformECC_0(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType, int criteria_type, int criteria_maxCount, double criteria_epsilon, long inputMask_nativeObj, int gaussFiltSize);</a>
<span class="sourceLineNo">1028</span><a id="line.1028"></a>
<span class="sourceLineNo">1029</span><a id="line.1029">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType = MOTION_AFFINE, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 50, 0.001), Mat inputMask = Mat())</a>
<span class="sourceLineNo">1030</span><a id="line.1030">    private static native double findTransformECC_1(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType, int criteria_type, int criteria_maxCount, double criteria_epsilon, long inputMask_nativeObj);</a>
<span class="sourceLineNo">1031</span><a id="line.1031">    private static native double findTransformECC_2(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">1032</span><a id="line.1032">    private static native double findTransformECC_3(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType);</a>
<span class="sourceLineNo">1033</span><a id="line.1033">    private static native double findTransformECC_4(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj);</a>
<span class="sourceLineNo">1034</span><a id="line.1034"></a>
<span class="sourceLineNo">1035</span><a id="line.1035">    // C++:  Mat cv::readOpticalFlow(String path)</a>
<span class="sourceLineNo">1036</span><a id="line.1036">    private static native long readOpticalFlow_0(String path);</a>
<span class="sourceLineNo">1037</span><a id="line.1037"></a>
<span class="sourceLineNo">1038</span><a id="line.1038">    // C++:  bool cv::writeOpticalFlow(String path, Mat flow)</a>
<span class="sourceLineNo">1039</span><a id="line.1039">    private static native boolean writeOpticalFlow_0(String path, long flow_nativeObj);</a>
<span class="sourceLineNo">1040</span><a id="line.1040"></a>
<span class="sourceLineNo">1041</span><a id="line.1041">}</a>




























































</pre>
</div>
</main>
</body>
</html>
