<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc -->
<title>Source code</title>
<meta name="description" content="source: package: org.opencv.video, class: Video">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body class="source">
<main role="main">
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span><a id="line.1">//</a>
<span class="sourceLineNo">002</span><a id="line.2">// This file is auto-generated. Please don't modify it!</a>
<span class="sourceLineNo">003</span><a id="line.3">//</a>
<span class="sourceLineNo">004</span><a id="line.4">package org.opencv.video;</a>
<span class="sourceLineNo">005</span><a id="line.5"></a>
<span class="sourceLineNo">006</span><a id="line.6">import java.util.ArrayList;</a>
<span class="sourceLineNo">007</span><a id="line.7">import java.util.List;</a>
<span class="sourceLineNo">008</span><a id="line.8">import org.opencv.core.Mat;</a>
<span class="sourceLineNo">009</span><a id="line.9">import org.opencv.core.MatOfByte;</a>
<span class="sourceLineNo">010</span><a id="line.10">import org.opencv.core.MatOfFloat;</a>
<span class="sourceLineNo">011</span><a id="line.11">import org.opencv.core.MatOfPoint2f;</a>
<span class="sourceLineNo">012</span><a id="line.12">import org.opencv.core.Rect;</a>
<span class="sourceLineNo">013</span><a id="line.13">import org.opencv.core.RotatedRect;</a>
<span class="sourceLineNo">014</span><a id="line.14">import org.opencv.core.Size;</a>
<span class="sourceLineNo">015</span><a id="line.15">import org.opencv.core.TermCriteria;</a>
<span class="sourceLineNo">016</span><a id="line.16">import org.opencv.utils.Converters;</a>
<span class="sourceLineNo">017</span><a id="line.17">import org.opencv.video.BackgroundSubtractorKNN;</a>
<span class="sourceLineNo">018</span><a id="line.18">import org.opencv.video.BackgroundSubtractorMOG2;</a>
<span class="sourceLineNo">019</span><a id="line.19"></a>
<span class="sourceLineNo">020</span><a id="line.20">// C++: class Video</a>
<span class="sourceLineNo">021</span><a id="line.21"></a>
<span class="sourceLineNo">022</span><a id="line.22">public class Video {</a>
<span class="sourceLineNo">023</span><a id="line.23"></a>
<span class="sourceLineNo">024</span><a id="line.24">    private static final int</a>
<span class="sourceLineNo">025</span><a id="line.25">            CV_LKFLOW_INITIAL_GUESSES = 4,</a>
<span class="sourceLineNo">026</span><a id="line.26">            CV_LKFLOW_GET_MIN_EIGENVALS = 8;</a>
<span class="sourceLineNo">027</span><a id="line.27"></a>
<span class="sourceLineNo">028</span><a id="line.28"></a>
<span class="sourceLineNo">029</span><a id="line.29">    // C++: enum &lt;unnamed&gt;</a>
<span class="sourceLineNo">030</span><a id="line.30">    public static final int</a>
<span class="sourceLineNo">031</span><a id="line.31">            OPTFLOW_USE_INITIAL_FLOW = 4,</a>
<span class="sourceLineNo">032</span><a id="line.32">            OPTFLOW_LK_GET_MIN_EIGENVALS = 8,</a>
<span class="sourceLineNo">033</span><a id="line.33">            OPTFLOW_FARNEBACK_GAUSSIAN = 256,</a>
<span class="sourceLineNo">034</span><a id="line.34">            MOTION_TRANSLATION = 0,</a>
<span class="sourceLineNo">035</span><a id="line.35">            MOTION_EUCLIDEAN = 1,</a>
<span class="sourceLineNo">036</span><a id="line.36">            MOTION_AFFINE = 2,</a>
<span class="sourceLineNo">037</span><a id="line.37">            MOTION_HOMOGRAPHY = 3;</a>
<span class="sourceLineNo">038</span><a id="line.38"></a>
<span class="sourceLineNo">039</span><a id="line.39"></a>
<span class="sourceLineNo">040</span><a id="line.40">    // C++: enum MODE (cv.detail.TrackerSamplerCSC.MODE)</a>
<span class="sourceLineNo">041</span><a id="line.41">    public static final int</a>
<span class="sourceLineNo">042</span><a id="line.42">            TrackerSamplerCSC_MODE_INIT_POS = 1,</a>
<span class="sourceLineNo">043</span><a id="line.43">            TrackerSamplerCSC_MODE_INIT_NEG = 2,</a>
<span class="sourceLineNo">044</span><a id="line.44">            TrackerSamplerCSC_MODE_TRACK_POS = 3,</a>
<span class="sourceLineNo">045</span><a id="line.45">            TrackerSamplerCSC_MODE_TRACK_NEG = 4,</a>
<span class="sourceLineNo">046</span><a id="line.46">            TrackerSamplerCSC_MODE_DETECT = 5;</a>
<span class="sourceLineNo">047</span><a id="line.47"></a>
<span class="sourceLineNo">048</span><a id="line.48"></a>
<span class="sourceLineNo">049</span><a id="line.49">    //</a>
<span class="sourceLineNo">050</span><a id="line.50">    // C++:  RotatedRect cv::CamShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">051</span><a id="line.51">    //</a>
<span class="sourceLineNo">052</span><a id="line.52"></a>
<span class="sourceLineNo">053</span><a id="line.53">    /**</a>
<span class="sourceLineNo">054</span><a id="line.54">     * Finds an object center, size, and orientation.</a>
<span class="sourceLineNo">055</span><a id="line.55">     *</a>
<span class="sourceLineNo">056</span><a id="line.56">     * @param probImage Back projection of the object histogram. See calcBackProject.</a>
<span class="sourceLineNo">057</span><a id="line.57">     * @param window Initial search window.</a>
<span class="sourceLineNo">058</span><a id="line.58">     * @param criteria Stop criteria for the underlying meanShift.</a>
<span class="sourceLineNo">059</span><a id="line.59">     * returns</a>
<span class="sourceLineNo">060</span><a id="line.60">     * (in old interfaces) Number of iterations CAMSHIFT took to converge</a>
<span class="sourceLineNo">061</span><a id="line.61">     * The function implements the CAMSHIFT object tracking algorithm CITE: Bradski98 . First, it finds an</a>
<span class="sourceLineNo">062</span><a id="line.62">     * object center using meanShift and then adjusts the window size and finds the optimal rotation. The</a>
<span class="sourceLineNo">063</span><a id="line.63">     * function returns the rotated rectangle structure that includes the object position, size, and</a>
<span class="sourceLineNo">064</span><a id="line.64">     * orientation. The next position of the search window can be obtained with RotatedRect::boundingRect()</a>
<span class="sourceLineNo">065</span><a id="line.65">     *</a>
<span class="sourceLineNo">066</span><a id="line.66">     * See the OpenCV sample camshiftdemo.c that tracks colored objects.</a>
<span class="sourceLineNo">067</span><a id="line.67">     *</a>
<span class="sourceLineNo">068</span><a id="line.68">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">069</span><a id="line.69">     * &lt;ul&gt;</a>
<span class="sourceLineNo">070</span><a id="line.70">     *   &lt;li&gt;</a>
<span class="sourceLineNo">071</span><a id="line.71">     *    (Python) A sample explaining the camshift tracking algorithm can be found at</a>
<span class="sourceLineNo">072</span><a id="line.72">     *     opencv_source_code/samples/python/camshift.py</a>
<span class="sourceLineNo">073</span><a id="line.73">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">074</span><a id="line.74">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">075</span><a id="line.75">     * @return automatically generated</a>
<span class="sourceLineNo">076</span><a id="line.76">     */</a>
<span class="sourceLineNo">077</span><a id="line.77">    public static RotatedRect CamShift(Mat probImage, Rect window, TermCriteria criteria) {</a>
<span class="sourceLineNo">078</span><a id="line.78">        double[] window_out = new double[4];</a>
<span class="sourceLineNo">079</span><a id="line.79">        RotatedRect retVal = new RotatedRect(CamShift_0(probImage.nativeObj, window.x, window.y, window.width, window.height, window_out, criteria.type, criteria.maxCount, criteria.epsilon));</a>
<span class="sourceLineNo">080</span><a id="line.80">        if(window!=null){ window.x = (int)window_out[0]; window.y = (int)window_out[1]; window.width = (int)window_out[2]; window.height = (int)window_out[3]; } </a>
<span class="sourceLineNo">081</span><a id="line.81">        return retVal;</a>
<span class="sourceLineNo">082</span><a id="line.82">    }</a>
<span class="sourceLineNo">083</span><a id="line.83"></a>
<span class="sourceLineNo">084</span><a id="line.84"></a>
<span class="sourceLineNo">085</span><a id="line.85">    //</a>
<span class="sourceLineNo">086</span><a id="line.86">    // C++:  int cv::meanShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">087</span><a id="line.87">    //</a>
<span class="sourceLineNo">088</span><a id="line.88"></a>
<span class="sourceLineNo">089</span><a id="line.89">    /**</a>
<span class="sourceLineNo">090</span><a id="line.90">     * Finds an object on a back projection image.</a>
<span class="sourceLineNo">091</span><a id="line.91">     *</a>
<span class="sourceLineNo">092</span><a id="line.92">     * @param probImage Back projection of the object histogram. See calcBackProject for details.</a>
<span class="sourceLineNo">093</span><a id="line.93">     * @param window Initial search window.</a>
<span class="sourceLineNo">094</span><a id="line.94">     * @param criteria Stop criteria for the iterative search algorithm.</a>
<span class="sourceLineNo">095</span><a id="line.95">     * returns</a>
<span class="sourceLineNo">096</span><a id="line.96">     * :   Number of iterations CAMSHIFT took to converge.</a>
<span class="sourceLineNo">097</span><a id="line.97">     * The function implements the iterative object search algorithm. It takes the input back projection of</a>
<span class="sourceLineNo">098</span><a id="line.98">     * an object and the initial position. The mass center in window of the back projection image is</a>
<span class="sourceLineNo">099</span><a id="line.99">     * computed and the search window center shifts to the mass center. The procedure is repeated until the</a>
<span class="sourceLineNo">100</span><a id="line.100">     * specified number of iterations criteria.maxCount is done or until the window center shifts by less</a>
<span class="sourceLineNo">101</span><a id="line.101">     * than criteria.epsilon. The algorithm is used inside CamShift and, unlike CamShift , the search</a>
<span class="sourceLineNo">102</span><a id="line.102">     * window size or orientation do not change during the search. You can simply pass the output of</a>
<span class="sourceLineNo">103</span><a id="line.103">     * calcBackProject to this function. But better results can be obtained if you pre-filter the back</a>
<span class="sourceLineNo">104</span><a id="line.104">     * projection and remove the noise. For example, you can do this by retrieving connected components</a>
<span class="sourceLineNo">105</span><a id="line.105">     * with findContours , throwing away contours with small area ( contourArea ), and rendering the</a>
<span class="sourceLineNo">106</span><a id="line.106">     * remaining contours with drawContours.</a>
<span class="sourceLineNo">107</span><a id="line.107">     * @return automatically generated</a>
<span class="sourceLineNo">108</span><a id="line.108">     */</a>
<span class="sourceLineNo">109</span><a id="line.109">    public static int meanShift(Mat probImage, Rect window, TermCriteria criteria) {</a>
<span class="sourceLineNo">110</span><a id="line.110">        double[] window_out = new double[4];</a>
<span class="sourceLineNo">111</span><a id="line.111">        int retVal = meanShift_0(probImage.nativeObj, window.x, window.y, window.width, window.height, window_out, criteria.type, criteria.maxCount, criteria.epsilon);</a>
<span class="sourceLineNo">112</span><a id="line.112">        if(window!=null){ window.x = (int)window_out[0]; window.y = (int)window_out[1]; window.width = (int)window_out[2]; window.height = (int)window_out[3]; } </a>
<span class="sourceLineNo">113</span><a id="line.113">        return retVal;</a>
<span class="sourceLineNo">114</span><a id="line.114">    }</a>
<span class="sourceLineNo">115</span><a id="line.115"></a>
<span class="sourceLineNo">116</span><a id="line.116"></a>
<span class="sourceLineNo">117</span><a id="line.117">    //</a>
<span class="sourceLineNo">118</span><a id="line.118">    // C++:  int cv::buildOpticalFlowPyramid(Mat img, vector_Mat&amp; pyramid, Size winSize, int maxLevel, bool withDerivatives = true, int pyrBorder = BORDER_REFLECT_101, int derivBorder = BORDER_CONSTANT, bool tryReuseInputImage = true)</a>
<span class="sourceLineNo">119</span><a id="line.119">    //</a>
<span class="sourceLineNo">120</span><a id="line.120"></a>
<span class="sourceLineNo">121</span><a id="line.121">    /**</a>
<span class="sourceLineNo">122</span><a id="line.122">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">123</span><a id="line.123">     *</a>
<span class="sourceLineNo">124</span><a id="line.124">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">125</span><a id="line.125">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">126</span><a id="line.126">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">127</span><a id="line.127">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">128</span><a id="line.128">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">129</span><a id="line.129">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">130</span><a id="line.130">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">131</span><a id="line.131">     * @param pyrBorder the border mode for pyramid layers.</a>
<span class="sourceLineNo">132</span><a id="line.132">     * @param derivBorder the border mode for gradients.</a>
<span class="sourceLineNo">133</span><a id="line.133">     * @param tryReuseInputImage put ROI of input image into the pyramid if possible. You can pass false</a>
<span class="sourceLineNo">134</span><a id="line.134">     * to force data copying.</a>
<span class="sourceLineNo">135</span><a id="line.135">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">136</span><a id="line.136">     */</a>
<span class="sourceLineNo">137</span><a id="line.137">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder, boolean tryReuseInputImage) {</a>
<span class="sourceLineNo">138</span><a id="line.138">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">139</span><a id="line.139">        int retVal = buildOpticalFlowPyramid_0(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives, pyrBorder, derivBorder, tryReuseInputImage);</a>
<span class="sourceLineNo">140</span><a id="line.140">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">141</span><a id="line.141">        pyramid_mat.release();</a>
<span class="sourceLineNo">142</span><a id="line.142">        return retVal;</a>
<span class="sourceLineNo">143</span><a id="line.143">    }</a>
<span class="sourceLineNo">144</span><a id="line.144"></a>
<span class="sourceLineNo">145</span><a id="line.145">    /**</a>
<span class="sourceLineNo">146</span><a id="line.146">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">147</span><a id="line.147">     *</a>
<span class="sourceLineNo">148</span><a id="line.148">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">149</span><a id="line.149">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">150</span><a id="line.150">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">151</span><a id="line.151">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">152</span><a id="line.152">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">153</span><a id="line.153">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">154</span><a id="line.154">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">155</span><a id="line.155">     * @param pyrBorder the border mode for pyramid layers.</a>
<span class="sourceLineNo">156</span><a id="line.156">     * @param derivBorder the border mode for gradients.</a>
<span class="sourceLineNo">157</span><a id="line.157">     * to force data copying.</a>
<span class="sourceLineNo">158</span><a id="line.158">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">159</span><a id="line.159">     */</a>
<span class="sourceLineNo">160</span><a id="line.160">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder) {</a>
<span class="sourceLineNo">161</span><a id="line.161">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">162</span><a id="line.162">        int retVal = buildOpticalFlowPyramid_1(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives, pyrBorder, derivBorder);</a>
<span class="sourceLineNo">163</span><a id="line.163">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">164</span><a id="line.164">        pyramid_mat.release();</a>
<span class="sourceLineNo">165</span><a id="line.165">        return retVal;</a>
<span class="sourceLineNo">166</span><a id="line.166">    }</a>
<span class="sourceLineNo">167</span><a id="line.167"></a>
<span class="sourceLineNo">168</span><a id="line.168">    /**</a>
<span class="sourceLineNo">169</span><a id="line.169">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">170</span><a id="line.170">     *</a>
<span class="sourceLineNo">171</span><a id="line.171">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">172</span><a id="line.172">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">173</span><a id="line.173">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">174</span><a id="line.174">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">175</span><a id="line.175">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">176</span><a id="line.176">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">177</span><a id="line.177">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">178</span><a id="line.178">     * @param pyrBorder the border mode for pyramid layers.</a>
<span class="sourceLineNo">179</span><a id="line.179">     * to force data copying.</a>
<span class="sourceLineNo">180</span><a id="line.180">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">181</span><a id="line.181">     */</a>
<span class="sourceLineNo">182</span><a id="line.182">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives, int pyrBorder) {</a>
<span class="sourceLineNo">183</span><a id="line.183">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">184</span><a id="line.184">        int retVal = buildOpticalFlowPyramid_2(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives, pyrBorder);</a>
<span class="sourceLineNo">185</span><a id="line.185">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">186</span><a id="line.186">        pyramid_mat.release();</a>
<span class="sourceLineNo">187</span><a id="line.187">        return retVal;</a>
<span class="sourceLineNo">188</span><a id="line.188">    }</a>
<span class="sourceLineNo">189</span><a id="line.189"></a>
<span class="sourceLineNo">190</span><a id="line.190">    /**</a>
<span class="sourceLineNo">191</span><a id="line.191">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">192</span><a id="line.192">     *</a>
<span class="sourceLineNo">193</span><a id="line.193">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">194</span><a id="line.194">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">195</span><a id="line.195">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">196</span><a id="line.196">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">197</span><a id="line.197">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">198</span><a id="line.198">     * @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is</a>
<span class="sourceLineNo">199</span><a id="line.199">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">200</span><a id="line.200">     * to force data copying.</a>
<span class="sourceLineNo">201</span><a id="line.201">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">202</span><a id="line.202">     */</a>
<span class="sourceLineNo">203</span><a id="line.203">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel, boolean withDerivatives) {</a>
<span class="sourceLineNo">204</span><a id="line.204">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">205</span><a id="line.205">        int retVal = buildOpticalFlowPyramid_3(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel, withDerivatives);</a>
<span class="sourceLineNo">206</span><a id="line.206">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">207</span><a id="line.207">        pyramid_mat.release();</a>
<span class="sourceLineNo">208</span><a id="line.208">        return retVal;</a>
<span class="sourceLineNo">209</span><a id="line.209">    }</a>
<span class="sourceLineNo">210</span><a id="line.210"></a>
<span class="sourceLineNo">211</span><a id="line.211">    /**</a>
<span class="sourceLineNo">212</span><a id="line.212">     * Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.</a>
<span class="sourceLineNo">213</span><a id="line.213">     *</a>
<span class="sourceLineNo">214</span><a id="line.214">     * @param img 8-bit input image.</a>
<span class="sourceLineNo">215</span><a id="line.215">     * @param pyramid output pyramid.</a>
<span class="sourceLineNo">216</span><a id="line.216">     * @param winSize window size of optical flow algorithm. Must be not less than winSize argument of</a>
<span class="sourceLineNo">217</span><a id="line.217">     * calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.</a>
<span class="sourceLineNo">218</span><a id="line.218">     * @param maxLevel 0-based maximal pyramid level number.</a>
<span class="sourceLineNo">219</span><a id="line.219">     * constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.</a>
<span class="sourceLineNo">220</span><a id="line.220">     * to force data copying.</a>
<span class="sourceLineNo">221</span><a id="line.221">     * @return number of levels in constructed pyramid. Can be less than maxLevel.</a>
<span class="sourceLineNo">222</span><a id="line.222">     */</a>
<span class="sourceLineNo">223</span><a id="line.223">    public static int buildOpticalFlowPyramid(Mat img, List&lt;Mat&gt; pyramid, Size winSize, int maxLevel) {</a>
<span class="sourceLineNo">224</span><a id="line.224">        Mat pyramid_mat = new Mat();</a>
<span class="sourceLineNo">225</span><a id="line.225">        int retVal = buildOpticalFlowPyramid_4(img.nativeObj, pyramid_mat.nativeObj, winSize.width, winSize.height, maxLevel);</a>
<span class="sourceLineNo">226</span><a id="line.226">        Converters.Mat_to_vector_Mat(pyramid_mat, pyramid);</a>
<span class="sourceLineNo">227</span><a id="line.227">        pyramid_mat.release();</a>
<span class="sourceLineNo">228</span><a id="line.228">        return retVal;</a>
<span class="sourceLineNo">229</span><a id="line.229">    }</a>
<span class="sourceLineNo">230</span><a id="line.230"></a>
<span class="sourceLineNo">231</span><a id="line.231"></a>
<span class="sourceLineNo">232</span><a id="line.232">    //</a>
<span class="sourceLineNo">233</span><a id="line.233">    // C++:  void cv::calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, vector_Point2f prevPts, vector_Point2f&amp; nextPts, vector_uchar&amp; status, vector_float&amp; err, Size winSize = Size(21,21), int maxLevel = 3, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01), int flags = 0, double minEigThreshold = 1e-4)</a>
<span class="sourceLineNo">234</span><a id="line.234">    //</a>
<span class="sourceLineNo">235</span><a id="line.235"></a>
<span class="sourceLineNo">236</span><a id="line.236">    /**</a>
<span class="sourceLineNo">237</span><a id="line.237">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">238</span><a id="line.238">     * pyramids.</a>
<span class="sourceLineNo">239</span><a id="line.239">     *</a>
<span class="sourceLineNo">240</span><a id="line.240">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">241</span><a id="line.241">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">242</span><a id="line.242">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">243</span><a id="line.243">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">244</span><a id="line.244">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">245</span><a id="line.245">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">246</span><a id="line.246">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">247</span><a id="line.247">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">248</span><a id="line.248">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">249</span><a id="line.249">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">250</span><a id="line.250">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">251</span><a id="line.251">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">252</span><a id="line.252">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">253</span><a id="line.253">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">254</span><a id="line.254">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">255</span><a id="line.255">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">256</span><a id="line.256">     * @param criteria parameter, specifying the termination criteria of the iterative search algorithm</a>
<span class="sourceLineNo">257</span><a id="line.257">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">258</span><a id="line.258">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">259</span><a id="line.259">     * @param flags operation flags:</a>
<span class="sourceLineNo">260</span><a id="line.260">     * &lt;ul&gt;</a>
<span class="sourceLineNo">261</span><a id="line.261">     *   &lt;li&gt;</a>
<span class="sourceLineNo">262</span><a id="line.262">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">263</span><a id="line.263">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">264</span><a id="line.264">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">265</span><a id="line.265">     *   &lt;li&gt;</a>
<span class="sourceLineNo">266</span><a id="line.266">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">267</span><a id="line.267">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">268</span><a id="line.268">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">269</span><a id="line.269">     *      error measure.</a>
<span class="sourceLineNo">270</span><a id="line.270">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">271</span><a id="line.271">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">272</span><a id="line.272">     * @param minEigThreshold the algorithm calculates the minimum eigen value of a 2x2 normal matrix of</a>
<span class="sourceLineNo">273</span><a id="line.273">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">274</span><a id="line.274">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">275</span><a id="line.275">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">276</span><a id="line.276">     * performance boost.</a>
<span class="sourceLineNo">277</span><a id="line.277">     *</a>
<span class="sourceLineNo">278</span><a id="line.278">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">279</span><a id="line.279">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">280</span><a id="line.280">     *</a>
<span class="sourceLineNo">281</span><a id="line.281">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">282</span><a id="line.282">     *</a>
<span class="sourceLineNo">283</span><a id="line.283">     * &lt;ul&gt;</a>
<span class="sourceLineNo">284</span><a id="line.284">     *   &lt;li&gt;</a>
<span class="sourceLineNo">285</span><a id="line.285">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">286</span><a id="line.286">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">287</span><a id="line.287">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">288</span><a id="line.288">     *   &lt;li&gt;</a>
<span class="sourceLineNo">289</span><a id="line.289">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">290</span><a id="line.290">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">291</span><a id="line.291">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">292</span><a id="line.292">     *   &lt;li&gt;</a>
<span class="sourceLineNo">293</span><a id="line.293">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">294</span><a id="line.294">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">295</span><a id="line.295">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">296</span><a id="line.296">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">297</span><a id="line.297">     */</a>
<span class="sourceLineNo">298</span><a id="line.298">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel, TermCriteria criteria, int flags, double minEigThreshold) {</a>
<span class="sourceLineNo">299</span><a id="line.299">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">300</span><a id="line.300">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">301</span><a id="line.301">        Mat status_mat = status;</a>
<span class="sourceLineNo">302</span><a id="line.302">        Mat err_mat = err;</a>
<span class="sourceLineNo">303</span><a id="line.303">        calcOpticalFlowPyrLK_0(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel, criteria.type, criteria.maxCount, criteria.epsilon, flags, minEigThreshold);</a>
<span class="sourceLineNo">304</span><a id="line.304">    }</a>
<span class="sourceLineNo">305</span><a id="line.305"></a>
<span class="sourceLineNo">306</span><a id="line.306">    /**</a>
<span class="sourceLineNo">307</span><a id="line.307">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">308</span><a id="line.308">     * pyramids.</a>
<span class="sourceLineNo">309</span><a id="line.309">     *</a>
<span class="sourceLineNo">310</span><a id="line.310">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">311</span><a id="line.311">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">312</span><a id="line.312">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">313</span><a id="line.313">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">314</span><a id="line.314">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">315</span><a id="line.315">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">316</span><a id="line.316">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">317</span><a id="line.317">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">318</span><a id="line.318">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">319</span><a id="line.319">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">320</span><a id="line.320">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">321</span><a id="line.321">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">322</span><a id="line.322">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">323</span><a id="line.323">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">324</span><a id="line.324">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">325</span><a id="line.325">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">326</span><a id="line.326">     * @param criteria parameter, specifying the termination criteria of the iterative search algorithm</a>
<span class="sourceLineNo">327</span><a id="line.327">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">328</span><a id="line.328">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">329</span><a id="line.329">     * @param flags operation flags:</a>
<span class="sourceLineNo">330</span><a id="line.330">     * &lt;ul&gt;</a>
<span class="sourceLineNo">331</span><a id="line.331">     *   &lt;li&gt;</a>
<span class="sourceLineNo">332</span><a id="line.332">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">333</span><a id="line.333">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">334</span><a id="line.334">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">335</span><a id="line.335">     *   &lt;li&gt;</a>
<span class="sourceLineNo">336</span><a id="line.336">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">337</span><a id="line.337">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">338</span><a id="line.338">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">339</span><a id="line.339">     *      error measure.</a>
<span class="sourceLineNo">340</span><a id="line.340">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">341</span><a id="line.341">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">342</span><a id="line.342">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">343</span><a id="line.343">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">344</span><a id="line.344">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">345</span><a id="line.345">     * performance boost.</a>
<span class="sourceLineNo">346</span><a id="line.346">     *</a>
<span class="sourceLineNo">347</span><a id="line.347">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">348</span><a id="line.348">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">349</span><a id="line.349">     *</a>
<span class="sourceLineNo">350</span><a id="line.350">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">351</span><a id="line.351">     *</a>
<span class="sourceLineNo">352</span><a id="line.352">     * &lt;ul&gt;</a>
<span class="sourceLineNo">353</span><a id="line.353">     *   &lt;li&gt;</a>
<span class="sourceLineNo">354</span><a id="line.354">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">355</span><a id="line.355">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">356</span><a id="line.356">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">357</span><a id="line.357">     *   &lt;li&gt;</a>
<span class="sourceLineNo">358</span><a id="line.358">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">359</span><a id="line.359">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">360</span><a id="line.360">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">361</span><a id="line.361">     *   &lt;li&gt;</a>
<span class="sourceLineNo">362</span><a id="line.362">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">363</span><a id="line.363">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">364</span><a id="line.364">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">365</span><a id="line.365">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">366</span><a id="line.366">     */</a>
<span class="sourceLineNo">367</span><a id="line.367">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel, TermCriteria criteria, int flags) {</a>
<span class="sourceLineNo">368</span><a id="line.368">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">369</span><a id="line.369">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">370</span><a id="line.370">        Mat status_mat = status;</a>
<span class="sourceLineNo">371</span><a id="line.371">        Mat err_mat = err;</a>
<span class="sourceLineNo">372</span><a id="line.372">        calcOpticalFlowPyrLK_1(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel, criteria.type, criteria.maxCount, criteria.epsilon, flags);</a>
<span class="sourceLineNo">373</span><a id="line.373">    }</a>
<span class="sourceLineNo">374</span><a id="line.374"></a>
<span class="sourceLineNo">375</span><a id="line.375">    /**</a>
<span class="sourceLineNo">376</span><a id="line.376">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">377</span><a id="line.377">     * pyramids.</a>
<span class="sourceLineNo">378</span><a id="line.378">     *</a>
<span class="sourceLineNo">379</span><a id="line.379">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">380</span><a id="line.380">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">381</span><a id="line.381">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">382</span><a id="line.382">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">383</span><a id="line.383">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">384</span><a id="line.384">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">385</span><a id="line.385">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">386</span><a id="line.386">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">387</span><a id="line.387">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">388</span><a id="line.388">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">389</span><a id="line.389">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">390</span><a id="line.390">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">391</span><a id="line.391">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">392</span><a id="line.392">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">393</span><a id="line.393">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">394</span><a id="line.394">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">395</span><a id="line.395">     * @param criteria parameter, specifying the termination criteria of the iterative search algorithm</a>
<span class="sourceLineNo">396</span><a id="line.396">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">397</span><a id="line.397">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">398</span><a id="line.398">     * &lt;ul&gt;</a>
<span class="sourceLineNo">399</span><a id="line.399">     *   &lt;li&gt;</a>
<span class="sourceLineNo">400</span><a id="line.400">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">401</span><a id="line.401">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">402</span><a id="line.402">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">403</span><a id="line.403">     *   &lt;li&gt;</a>
<span class="sourceLineNo">404</span><a id="line.404">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">405</span><a id="line.405">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">406</span><a id="line.406">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">407</span><a id="line.407">     *      error measure.</a>
<span class="sourceLineNo">408</span><a id="line.408">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">409</span><a id="line.409">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">410</span><a id="line.410">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">411</span><a id="line.411">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">412</span><a id="line.412">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">413</span><a id="line.413">     * performance boost.</a>
<span class="sourceLineNo">414</span><a id="line.414">     *</a>
<span class="sourceLineNo">415</span><a id="line.415">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">416</span><a id="line.416">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">417</span><a id="line.417">     *</a>
<span class="sourceLineNo">418</span><a id="line.418">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">419</span><a id="line.419">     *</a>
<span class="sourceLineNo">420</span><a id="line.420">     * &lt;ul&gt;</a>
<span class="sourceLineNo">421</span><a id="line.421">     *   &lt;li&gt;</a>
<span class="sourceLineNo">422</span><a id="line.422">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">423</span><a id="line.423">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">424</span><a id="line.424">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">425</span><a id="line.425">     *   &lt;li&gt;</a>
<span class="sourceLineNo">426</span><a id="line.426">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">427</span><a id="line.427">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">428</span><a id="line.428">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">429</span><a id="line.429">     *   &lt;li&gt;</a>
<span class="sourceLineNo">430</span><a id="line.430">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">431</span><a id="line.431">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">432</span><a id="line.432">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">433</span><a id="line.433">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">434</span><a id="line.434">     */</a>
<span class="sourceLineNo">435</span><a id="line.435">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel, TermCriteria criteria) {</a>
<span class="sourceLineNo">436</span><a id="line.436">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">437</span><a id="line.437">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">438</span><a id="line.438">        Mat status_mat = status;</a>
<span class="sourceLineNo">439</span><a id="line.439">        Mat err_mat = err;</a>
<span class="sourceLineNo">440</span><a id="line.440">        calcOpticalFlowPyrLK_2(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel, criteria.type, criteria.maxCount, criteria.epsilon);</a>
<span class="sourceLineNo">441</span><a id="line.441">    }</a>
<span class="sourceLineNo">442</span><a id="line.442"></a>
<span class="sourceLineNo">443</span><a id="line.443">    /**</a>
<span class="sourceLineNo">444</span><a id="line.444">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">445</span><a id="line.445">     * pyramids.</a>
<span class="sourceLineNo">446</span><a id="line.446">     *</a>
<span class="sourceLineNo">447</span><a id="line.447">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">448</span><a id="line.448">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">449</span><a id="line.449">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">450</span><a id="line.450">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">451</span><a id="line.451">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">452</span><a id="line.452">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">453</span><a id="line.453">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">454</span><a id="line.454">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">455</span><a id="line.455">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">456</span><a id="line.456">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">457</span><a id="line.457">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">458</span><a id="line.458">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">459</span><a id="line.459">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">460</span><a id="line.460">     * @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single</a>
<span class="sourceLineNo">461</span><a id="line.461">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">462</span><a id="line.462">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">463</span><a id="line.463">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">464</span><a id="line.464">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">465</span><a id="line.465">     * &lt;ul&gt;</a>
<span class="sourceLineNo">466</span><a id="line.466">     *   &lt;li&gt;</a>
<span class="sourceLineNo">467</span><a id="line.467">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">468</span><a id="line.468">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">469</span><a id="line.469">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">470</span><a id="line.470">     *   &lt;li&gt;</a>
<span class="sourceLineNo">471</span><a id="line.471">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">472</span><a id="line.472">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">473</span><a id="line.473">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">474</span><a id="line.474">     *      error measure.</a>
<span class="sourceLineNo">475</span><a id="line.475">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">476</span><a id="line.476">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">477</span><a id="line.477">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">478</span><a id="line.478">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">479</span><a id="line.479">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">480</span><a id="line.480">     * performance boost.</a>
<span class="sourceLineNo">481</span><a id="line.481">     *</a>
<span class="sourceLineNo">482</span><a id="line.482">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">483</span><a id="line.483">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">484</span><a id="line.484">     *</a>
<span class="sourceLineNo">485</span><a id="line.485">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">486</span><a id="line.486">     *</a>
<span class="sourceLineNo">487</span><a id="line.487">     * &lt;ul&gt;</a>
<span class="sourceLineNo">488</span><a id="line.488">     *   &lt;li&gt;</a>
<span class="sourceLineNo">489</span><a id="line.489">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">490</span><a id="line.490">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">491</span><a id="line.491">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">492</span><a id="line.492">     *   &lt;li&gt;</a>
<span class="sourceLineNo">493</span><a id="line.493">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">494</span><a id="line.494">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">495</span><a id="line.495">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">496</span><a id="line.496">     *   &lt;li&gt;</a>
<span class="sourceLineNo">497</span><a id="line.497">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">498</span><a id="line.498">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">499</span><a id="line.499">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">500</span><a id="line.500">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">501</span><a id="line.501">     */</a>
<span class="sourceLineNo">502</span><a id="line.502">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize, int maxLevel) {</a>
<span class="sourceLineNo">503</span><a id="line.503">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">504</span><a id="line.504">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">505</span><a id="line.505">        Mat status_mat = status;</a>
<span class="sourceLineNo">506</span><a id="line.506">        Mat err_mat = err;</a>
<span class="sourceLineNo">507</span><a id="line.507">        calcOpticalFlowPyrLK_3(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height, maxLevel);</a>
<span class="sourceLineNo">508</span><a id="line.508">    }</a>
<span class="sourceLineNo">509</span><a id="line.509"></a>
<span class="sourceLineNo">510</span><a id="line.510">    /**</a>
<span class="sourceLineNo">511</span><a id="line.511">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">512</span><a id="line.512">     * pyramids.</a>
<span class="sourceLineNo">513</span><a id="line.513">     *</a>
<span class="sourceLineNo">514</span><a id="line.514">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">515</span><a id="line.515">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">516</span><a id="line.516">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">517</span><a id="line.517">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">518</span><a id="line.518">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">519</span><a id="line.519">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">520</span><a id="line.520">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">521</span><a id="line.521">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">522</span><a id="line.522">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">523</span><a id="line.523">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">524</span><a id="line.524">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">525</span><a id="line.525">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">526</span><a id="line.526">     * @param winSize size of the search window at each pyramid level.</a>
<span class="sourceLineNo">527</span><a id="line.527">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">528</span><a id="line.528">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">529</span><a id="line.529">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">530</span><a id="line.530">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">531</span><a id="line.531">     * &lt;ul&gt;</a>
<span class="sourceLineNo">532</span><a id="line.532">     *   &lt;li&gt;</a>
<span class="sourceLineNo">533</span><a id="line.533">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">534</span><a id="line.534">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">535</span><a id="line.535">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">536</span><a id="line.536">     *   &lt;li&gt;</a>
<span class="sourceLineNo">537</span><a id="line.537">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">538</span><a id="line.538">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">539</span><a id="line.539">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">540</span><a id="line.540">     *      error measure.</a>
<span class="sourceLineNo">541</span><a id="line.541">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">542</span><a id="line.542">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">543</span><a id="line.543">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">544</span><a id="line.544">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">545</span><a id="line.545">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">546</span><a id="line.546">     * performance boost.</a>
<span class="sourceLineNo">547</span><a id="line.547">     *</a>
<span class="sourceLineNo">548</span><a id="line.548">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">549</span><a id="line.549">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">550</span><a id="line.550">     *</a>
<span class="sourceLineNo">551</span><a id="line.551">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">552</span><a id="line.552">     *</a>
<span class="sourceLineNo">553</span><a id="line.553">     * &lt;ul&gt;</a>
<span class="sourceLineNo">554</span><a id="line.554">     *   &lt;li&gt;</a>
<span class="sourceLineNo">555</span><a id="line.555">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">556</span><a id="line.556">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">557</span><a id="line.557">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">558</span><a id="line.558">     *   &lt;li&gt;</a>
<span class="sourceLineNo">559</span><a id="line.559">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">560</span><a id="line.560">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">561</span><a id="line.561">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">562</span><a id="line.562">     *   &lt;li&gt;</a>
<span class="sourceLineNo">563</span><a id="line.563">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">564</span><a id="line.564">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">565</span><a id="line.565">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">566</span><a id="line.566">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">567</span><a id="line.567">     */</a>
<span class="sourceLineNo">568</span><a id="line.568">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err, Size winSize) {</a>
<span class="sourceLineNo">569</span><a id="line.569">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">570</span><a id="line.570">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">571</span><a id="line.571">        Mat status_mat = status;</a>
<span class="sourceLineNo">572</span><a id="line.572">        Mat err_mat = err;</a>
<span class="sourceLineNo">573</span><a id="line.573">        calcOpticalFlowPyrLK_4(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj, winSize.width, winSize.height);</a>
<span class="sourceLineNo">574</span><a id="line.574">    }</a>
<span class="sourceLineNo">575</span><a id="line.575"></a>
<span class="sourceLineNo">576</span><a id="line.576">    /**</a>
<span class="sourceLineNo">577</span><a id="line.577">     * Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with</a>
<span class="sourceLineNo">578</span><a id="line.578">     * pyramids.</a>
<span class="sourceLineNo">579</span><a id="line.579">     *</a>
<span class="sourceLineNo">580</span><a id="line.580">     * @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.</a>
<span class="sourceLineNo">581</span><a id="line.581">     * @param nextImg second input image or pyramid of the same size and the same type as prevImg.</a>
<span class="sourceLineNo">582</span><a id="line.582">     * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be</a>
<span class="sourceLineNo">583</span><a id="line.583">     * single-precision floating-point numbers.</a>
<span class="sourceLineNo">584</span><a id="line.584">     * @param nextPts output vector of 2D points (with single-precision floating-point coordinates)</a>
<span class="sourceLineNo">585</span><a id="line.585">     * containing the calculated new positions of input features in the second image; when</a>
<span class="sourceLineNo">586</span><a id="line.586">     * OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.</a>
<span class="sourceLineNo">587</span><a id="line.587">     * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if</a>
<span class="sourceLineNo">588</span><a id="line.588">     * the flow for the corresponding features has been found, otherwise, it is set to 0.</a>
<span class="sourceLineNo">589</span><a id="line.589">     * @param err output vector of errors; each element of the vector is set to an error for the</a>
<span class="sourceLineNo">590</span><a id="line.590">     * corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't</a>
<span class="sourceLineNo">591</span><a id="line.591">     * found then the error is not defined (use the status parameter to find such cases).</a>
<span class="sourceLineNo">592</span><a id="line.592">     * level), if set to 1, two levels are used, and so on; if pyramids are passed to input then</a>
<span class="sourceLineNo">593</span><a id="line.593">     * algorithm will use as many levels as pyramids have but no more than maxLevel.</a>
<span class="sourceLineNo">594</span><a id="line.594">     * (after the specified maximum number of iterations criteria.maxCount or when the search window</a>
<span class="sourceLineNo">595</span><a id="line.595">     * moves by less than criteria.epsilon.</a>
<span class="sourceLineNo">596</span><a id="line.596">     * &lt;ul&gt;</a>
<span class="sourceLineNo">597</span><a id="line.597">     *   &lt;li&gt;</a>
<span class="sourceLineNo">598</span><a id="line.598">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses initial estimations, stored in nextPts; if the flag is</a>
<span class="sourceLineNo">599</span><a id="line.599">     *      not set, then prevPts is copied to nextPts and is considered the initial estimate.</a>
<span class="sourceLineNo">600</span><a id="line.600">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">601</span><a id="line.601">     *   &lt;li&gt;</a>
<span class="sourceLineNo">602</span><a id="line.602">     *     &lt;b&gt;OPTFLOW_LK_GET_MIN_EIGENVALS&lt;/b&gt; use minimum eigen values as an error measure (see</a>
<span class="sourceLineNo">603</span><a id="line.603">     *      minEigThreshold description); if the flag is not set, then L1 distance between patches</a>
<span class="sourceLineNo">604</span><a id="line.604">     *      around the original and a moved point, divided by number of pixels in a window, is used as a</a>
<span class="sourceLineNo">605</span><a id="line.605">     *      error measure.</a>
<span class="sourceLineNo">606</span><a id="line.606">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">607</span><a id="line.607">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">608</span><a id="line.608">     * optical flow equations (this matrix is called a spatial gradient matrix in CITE: Bouguet00), divided</a>
<span class="sourceLineNo">609</span><a id="line.609">     * by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding</a>
<span class="sourceLineNo">610</span><a id="line.610">     * feature is filtered out and its flow is not processed, so it allows to remove bad points and get a</a>
<span class="sourceLineNo">611</span><a id="line.611">     * performance boost.</a>
<span class="sourceLineNo">612</span><a id="line.612">     *</a>
<span class="sourceLineNo">613</span><a id="line.613">     * The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See</a>
<span class="sourceLineNo">614</span><a id="line.614">     * CITE: Bouguet00 . The function is parallelized with the TBB library.</a>
<span class="sourceLineNo">615</span><a id="line.615">     *</a>
<span class="sourceLineNo">616</span><a id="line.616">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">617</span><a id="line.617">     *</a>
<span class="sourceLineNo">618</span><a id="line.618">     * &lt;ul&gt;</a>
<span class="sourceLineNo">619</span><a id="line.619">     *   &lt;li&gt;</a>
<span class="sourceLineNo">620</span><a id="line.620">     *    An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">621</span><a id="line.621">     *     opencv_source_code/samples/cpp/lkdemo.cpp</a>
<span class="sourceLineNo">622</span><a id="line.622">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">623</span><a id="line.623">     *   &lt;li&gt;</a>
<span class="sourceLineNo">624</span><a id="line.624">     *    (Python) An example using the Lucas-Kanade optical flow algorithm can be found at</a>
<span class="sourceLineNo">625</span><a id="line.625">     *     opencv_source_code/samples/python/lk_track.py</a>
<span class="sourceLineNo">626</span><a id="line.626">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">627</span><a id="line.627">     *   &lt;li&gt;</a>
<span class="sourceLineNo">628</span><a id="line.628">     *    (Python) An example using the Lucas-Kanade tracker for homography matching can be found at</a>
<span class="sourceLineNo">629</span><a id="line.629">     *     opencv_source_code/samples/python/lk_homography.py</a>
<span class="sourceLineNo">630</span><a id="line.630">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">631</span><a id="line.631">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">632</span><a id="line.632">     */</a>
<span class="sourceLineNo">633</span><a id="line.633">    public static void calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, MatOfPoint2f prevPts, MatOfPoint2f nextPts, MatOfByte status, MatOfFloat err) {</a>
<span class="sourceLineNo">634</span><a id="line.634">        Mat prevPts_mat = prevPts;</a>
<span class="sourceLineNo">635</span><a id="line.635">        Mat nextPts_mat = nextPts;</a>
<span class="sourceLineNo">636</span><a id="line.636">        Mat status_mat = status;</a>
<span class="sourceLineNo">637</span><a id="line.637">        Mat err_mat = err;</a>
<span class="sourceLineNo">638</span><a id="line.638">        calcOpticalFlowPyrLK_5(prevImg.nativeObj, nextImg.nativeObj, prevPts_mat.nativeObj, nextPts_mat.nativeObj, status_mat.nativeObj, err_mat.nativeObj);</a>
<span class="sourceLineNo">639</span><a id="line.639">    }</a>
<span class="sourceLineNo">640</span><a id="line.640"></a>
<span class="sourceLineNo">641</span><a id="line.641"></a>
<span class="sourceLineNo">642</span><a id="line.642">    //</a>
<span class="sourceLineNo">643</span><a id="line.643">    // C++:  void cv::calcOpticalFlowFarneback(Mat prev, Mat next, Mat&amp; flow, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags)</a>
<span class="sourceLineNo">644</span><a id="line.644">    //</a>
<span class="sourceLineNo">645</span><a id="line.645"></a>
<span class="sourceLineNo">646</span><a id="line.646">    /**</a>
<span class="sourceLineNo">647</span><a id="line.647">     * Computes a dense optical flow using the Gunnar Farneback's algorithm.</a>
<span class="sourceLineNo">648</span><a id="line.648">     *</a>
<span class="sourceLineNo">649</span><a id="line.649">     * @param prev first 8-bit single-channel input image.</a>
<span class="sourceLineNo">650</span><a id="line.650">     * @param next second input image of the same size and the same type as prev.</a>
<span class="sourceLineNo">651</span><a id="line.651">     * @param flow computed flow image that has the same size as prev and type CV_32FC2.</a>
<span class="sourceLineNo">652</span><a id="line.652">     * @param pyr_scale parameter, specifying the image scale (&amp;lt;1) to build pyramids for each image;</a>
<span class="sourceLineNo">653</span><a id="line.653">     * pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous</a>
<span class="sourceLineNo">654</span><a id="line.654">     * one.</a>
<span class="sourceLineNo">655</span><a id="line.655">     * @param levels number of pyramid layers including the initial image; levels=1 means that no extra</a>
<span class="sourceLineNo">656</span><a id="line.656">     * layers are created and only the original images are used.</a>
<span class="sourceLineNo">657</span><a id="line.657">     * @param winsize averaging window size; larger values increase the algorithm robustness to image</a>
<span class="sourceLineNo">658</span><a id="line.658">     * noise and give more chances for fast motion detection, but yield more blurred motion field.</a>
<span class="sourceLineNo">659</span><a id="line.659">     * @param iterations number of iterations the algorithm does at each pyramid level.</a>
<span class="sourceLineNo">660</span><a id="line.660">     * @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;</a>
<span class="sourceLineNo">661</span><a id="line.661">     * larger values mean that the image will be approximated with smoother surfaces, yielding more</a>
<span class="sourceLineNo">662</span><a id="line.662">     * robust algorithm and more blurred motion field, typically poly_n =5 or 7.</a>
<span class="sourceLineNo">663</span><a id="line.663">     * @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a</a>
<span class="sourceLineNo">664</span><a id="line.664">     * basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a</a>
<span class="sourceLineNo">665</span><a id="line.665">     * good value would be poly_sigma=1.5.</a>
<span class="sourceLineNo">666</span><a id="line.666">     * @param flags operation flags that can be a combination of the following:</a>
<span class="sourceLineNo">667</span><a id="line.667">     * &lt;ul&gt;</a>
<span class="sourceLineNo">668</span><a id="line.668">     *   &lt;li&gt;</a>
<span class="sourceLineNo">669</span><a id="line.669">     *     &lt;b&gt;OPTFLOW_USE_INITIAL_FLOW&lt;/b&gt; uses the input flow as an initial flow approximation.</a>
<span class="sourceLineNo">670</span><a id="line.670">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">671</span><a id="line.671">     *   &lt;li&gt;</a>
<span class="sourceLineNo">672</span><a id="line.672">     *     &lt;b&gt;OPTFLOW_FARNEBACK_GAUSSIAN&lt;/b&gt; uses the Gaussian \(\texttt{winsize}\times\texttt{winsize}\)</a>
<span class="sourceLineNo">673</span><a id="line.673">     *      filter instead of a box filter of the same size for optical flow estimation; usually, this</a>
<span class="sourceLineNo">674</span><a id="line.674">     *      option gives z more accurate flow than with a box filter, at the cost of lower speed;</a>
<span class="sourceLineNo">675</span><a id="line.675">     *      normally, winsize for a Gaussian window should be set to a larger value to achieve the same</a>
<span class="sourceLineNo">676</span><a id="line.676">     *      level of robustness.</a>
<span class="sourceLineNo">677</span><a id="line.677">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">678</span><a id="line.678">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">679</span><a id="line.679">     *</a>
<span class="sourceLineNo">680</span><a id="line.680">     * The function finds an optical flow for each prev pixel using the CITE: Farneback2003 algorithm so that</a>
<span class="sourceLineNo">681</span><a id="line.681">     *</a>
<span class="sourceLineNo">682</span><a id="line.682">     * \(\texttt{prev} (y,x)  \sim \texttt{next} ( y + \texttt{flow} (y,x)[1],  x + \texttt{flow} (y,x)[0])\)</a>
<span class="sourceLineNo">683</span><a id="line.683">     *</a>
<span class="sourceLineNo">684</span><a id="line.684">     * &lt;b&gt;Note:&lt;/b&gt;</a>
<span class="sourceLineNo">685</span><a id="line.685">     *</a>
<span class="sourceLineNo">686</span><a id="line.686">     * &lt;ul&gt;</a>
<span class="sourceLineNo">687</span><a id="line.687">     *   &lt;li&gt;</a>
<span class="sourceLineNo">688</span><a id="line.688">     *    An example using the optical flow algorithm described by Gunnar Farneback can be found at</a>
<span class="sourceLineNo">689</span><a id="line.689">     *     opencv_source_code/samples/cpp/fback.cpp</a>
<span class="sourceLineNo">690</span><a id="line.690">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">691</span><a id="line.691">     *   &lt;li&gt;</a>
<span class="sourceLineNo">692</span><a id="line.692">     *    (Python) An example using the optical flow algorithm described by Gunnar Farneback can be</a>
<span class="sourceLineNo">693</span><a id="line.693">     *     found at opencv_source_code/samples/python/opt_flow.py</a>
<span class="sourceLineNo">694</span><a id="line.694">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">695</span><a id="line.695">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">696</span><a id="line.696">     */</a>
<span class="sourceLineNo">697</span><a id="line.697">    public static void calcOpticalFlowFarneback(Mat prev, Mat next, Mat flow, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags) {</a>
<span class="sourceLineNo">698</span><a id="line.698">        calcOpticalFlowFarneback_0(prev.nativeObj, next.nativeObj, flow.nativeObj, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags);</a>
<span class="sourceLineNo">699</span><a id="line.699">    }</a>
<span class="sourceLineNo">700</span><a id="line.700"></a>
<span class="sourceLineNo">701</span><a id="line.701"></a>
<span class="sourceLineNo">702</span><a id="line.702">    //</a>
<span class="sourceLineNo">703</span><a id="line.703">    // C++:  double cv::computeECC(Mat templateImage, Mat inputImage, Mat inputMask = Mat())</a>
<span class="sourceLineNo">704</span><a id="line.704">    //</a>
<span class="sourceLineNo">705</span><a id="line.705"></a>
<span class="sourceLineNo">706</span><a id="line.706">    /**</a>
<span class="sourceLineNo">707</span><a id="line.707">     * Computes the Enhanced Correlation Coefficient value between two images CITE: EP08 .</a>
<span class="sourceLineNo">708</span><a id="line.708">     *</a>
<span class="sourceLineNo">709</span><a id="line.709">     * @param templateImage single-channel template image; CV_8U or CV_32F array.</a>
<span class="sourceLineNo">710</span><a id="line.710">     * @param inputImage single-channel input image to be warped to provide an image similar to</a>
<span class="sourceLineNo">711</span><a id="line.711">     *  templateImage, same type as templateImage.</a>
<span class="sourceLineNo">712</span><a id="line.712">     * @param inputMask An optional mask to indicate valid values of inputImage.</a>
<span class="sourceLineNo">713</span><a id="line.713">     *</a>
<span class="sourceLineNo">714</span><a id="line.714">     * SEE:</a>
<span class="sourceLineNo">715</span><a id="line.715">     * findTransformECC</a>
<span class="sourceLineNo">716</span><a id="line.716">     * @return automatically generated</a>
<span class="sourceLineNo">717</span><a id="line.717">     */</a>
<span class="sourceLineNo">718</span><a id="line.718">    public static double computeECC(Mat templateImage, Mat inputImage, Mat inputMask) {</a>
<span class="sourceLineNo">719</span><a id="line.719">        return computeECC_0(templateImage.nativeObj, inputImage.nativeObj, inputMask.nativeObj);</a>
<span class="sourceLineNo">720</span><a id="line.720">    }</a>
<span class="sourceLineNo">721</span><a id="line.721"></a>
<span class="sourceLineNo">722</span><a id="line.722">    /**</a>
<span class="sourceLineNo">723</span><a id="line.723">     * Computes the Enhanced Correlation Coefficient value between two images CITE: EP08 .</a>
<span class="sourceLineNo">724</span><a id="line.724">     *</a>
<span class="sourceLineNo">725</span><a id="line.725">     * @param templateImage single-channel template image; CV_8U or CV_32F array.</a>
<span class="sourceLineNo">726</span><a id="line.726">     * @param inputImage single-channel input image to be warped to provide an image similar to</a>
<span class="sourceLineNo">727</span><a id="line.727">     *  templateImage, same type as templateImage.</a>
<span class="sourceLineNo">728</span><a id="line.728">     *</a>
<span class="sourceLineNo">729</span><a id="line.729">     * SEE:</a>
<span class="sourceLineNo">730</span><a id="line.730">     * findTransformECC</a>
<span class="sourceLineNo">731</span><a id="line.731">     * @return automatically generated</a>
<span class="sourceLineNo">732</span><a id="line.732">     */</a>
<span class="sourceLineNo">733</span><a id="line.733">    public static double computeECC(Mat templateImage, Mat inputImage) {</a>
<span class="sourceLineNo">734</span><a id="line.734">        return computeECC_1(templateImage.nativeObj, inputImage.nativeObj);</a>
<span class="sourceLineNo">735</span><a id="line.735">    }</a>
<span class="sourceLineNo">736</span><a id="line.736"></a>
<span class="sourceLineNo">737</span><a id="line.737"></a>
<span class="sourceLineNo">738</span><a id="line.738">    //</a>
<span class="sourceLineNo">739</span><a id="line.739">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize)</a>
<span class="sourceLineNo">740</span><a id="line.740">    //</a>
<span class="sourceLineNo">741</span><a id="line.741"></a>
<span class="sourceLineNo">742</span><a id="line.742">    /**</a>
<span class="sourceLineNo">743</span><a id="line.743">     * Finds the geometric transform (warp) between two images in terms of the ECC criterion CITE: EP08 .</a>
<span class="sourceLineNo">744</span><a id="line.744">     *</a>
<span class="sourceLineNo">745</span><a id="line.745">     * @param templateImage single-channel template image; CV_8U or CV_32F array.</a>
<span class="sourceLineNo">746</span><a id="line.746">     * @param inputImage single-channel input image which should be warped with the final warpMatrix in</a>
<span class="sourceLineNo">747</span><a id="line.747">     * order to provide an image similar to templateImage, same type as templateImage.</a>
<span class="sourceLineNo">748</span><a id="line.748">     * @param warpMatrix floating-point \(2\times 3\) or \(3\times 3\) mapping matrix (warp).</a>
<span class="sourceLineNo">749</span><a id="line.749">     * @param motionType parameter, specifying the type of motion:</a>
<span class="sourceLineNo">750</span><a id="line.750">     * &lt;ul&gt;</a>
<span class="sourceLineNo">751</span><a id="line.751">     *   &lt;li&gt;</a>
<span class="sourceLineNo">752</span><a id="line.752">     *     &lt;b&gt;MOTION_TRANSLATION&lt;/b&gt; sets a translational motion model; warpMatrix is \(2\times 3\) with</a>
<span class="sourceLineNo">753</span><a id="line.753">     *      the first \(2\times 2\) part being the unity matrix and the rest two parameters being</a>
<span class="sourceLineNo">754</span><a id="line.754">     *      estimated.</a>
<span class="sourceLineNo">755</span><a id="line.755">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">756</span><a id="line.756">     *   &lt;li&gt;</a>
<span class="sourceLineNo">757</span><a id="line.757">     *     &lt;b&gt;MOTION_EUCLIDEAN&lt;/b&gt; sets a Euclidean (rigid) transformation as motion model; three</a>
<span class="sourceLineNo">758</span><a id="line.758">     *      parameters are estimated; warpMatrix is \(2\times 3\).</a>
<span class="sourceLineNo">759</span><a id="line.759">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">760</span><a id="line.760">     *   &lt;li&gt;</a>
<span class="sourceLineNo">761</span><a id="line.761">     *     &lt;b&gt;MOTION_AFFINE&lt;/b&gt; sets an affine motion model (DEFAULT); six parameters are estimated;</a>
<span class="sourceLineNo">762</span><a id="line.762">     *      warpMatrix is \(2\times 3\).</a>
<span class="sourceLineNo">763</span><a id="line.763">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">764</span><a id="line.764">     *   &lt;li&gt;</a>
<span class="sourceLineNo">765</span><a id="line.765">     *     &lt;b&gt;MOTION_HOMOGRAPHY&lt;/b&gt; sets a homography as a motion model; eight parameters are</a>
<span class="sourceLineNo">766</span><a id="line.766">     *      estimated;\{@code warpMatrix\} is \(3\times 3\).</a>
<span class="sourceLineNo">767</span><a id="line.767">     *   &lt;/li&gt;</a>
<span class="sourceLineNo">768</span><a id="line.768">     * &lt;/ul&gt;</a>
<span class="sourceLineNo">769</span><a id="line.769">     * @param criteria parameter, specifying the termination criteria of the ECC algorithm;</a>
<span class="sourceLineNo">770</span><a id="line.770">     * criteria.epsilon defines the threshold of the increment in the correlation coefficient between two</a>
<span class="sourceLineNo">771</span><a id="line.771">     * iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion).</a>
<span class="sourceLineNo">772</span><a id="line.772">     * Default values are shown in the declaration above.</a>
<span class="sourceLineNo">773</span><a id="line.773">     * @param inputMask An optional mask to indicate valid values of inputImage.</a>
<span class="sourceLineNo">774</span><a id="line.774">     * @param gaussFiltSize An optional value indicating size of gaussian blur filter; (DEFAULT: 5)</a>
<span class="sourceLineNo">775</span><a id="line.775">     *</a>
<span class="sourceLineNo">776</span><a id="line.776">     * The function estimates the optimum transformation (warpMatrix) with respect to ECC criterion</a>
<span class="sourceLineNo">777</span><a id="line.777">     * (CITE: EP08), that is</a>
<span class="sourceLineNo">778</span><a id="line.778">     *</a>
<span class="sourceLineNo">779</span><a id="line.779">     * \(\texttt{warpMatrix} = \arg\max_{W} \texttt{ECC}(\texttt{templateImage}(x,y),\texttt{inputImage}(x',y'))\)</a>
<span class="sourceLineNo">780</span><a id="line.780">     *</a>
<span class="sourceLineNo">781</span><a id="line.781">     * where</a>
<span class="sourceLineNo">782</span><a id="line.782">     *</a>
<span class="sourceLineNo">783</span><a id="line.783">     * \(\begin{bmatrix} x' \\ y' \end{bmatrix} = W \cdot \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}\)</a>
<span class="sourceLineNo">784</span><a id="line.784">     *</a>
<span class="sourceLineNo">785</span><a id="line.785">     * (the equation holds with homogeneous coordinates for homography). It returns the final enhanced</a>
<span class="sourceLineNo">786</span><a id="line.786">     * correlation coefficient, that is the correlation coefficient between the template image and the</a>
<span class="sourceLineNo">787</span><a id="line.787">     * final warped input image. When a \(3\times 3\) matrix is given with motionType =0, 1 or 2, the third</a>
<span class="sourceLineNo">788</span><a id="line.788">     * row is ignored.</a>
<span class="sourceLineNo">789</span><a id="line.789">     *</a>
<span class="sourceLineNo">790</span><a id="line.790">     * Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an</a>
<span class="sourceLineNo">791</span><a id="line.791">     * area-based alignment that builds on intensity similarities. In essence, the function updates the</a>
<span class="sourceLineNo">792</span><a id="line.792">     * initial transformation that roughly aligns the images. If this information is missing, the identity</a>
<span class="sourceLineNo">793</span><a id="line.793">     * warp (unity matrix) is used as an initialization. Note that if images undergo strong</a>
<span class="sourceLineNo">794</span><a id="line.794">     * displacements/rotations, an initial transformation that roughly aligns the images is necessary</a>
<span class="sourceLineNo">795</span><a id="line.795">     * (e.g., a simple euclidean/similarity transform that allows for the images showing the same image</a>
<span class="sourceLineNo">796</span><a id="line.796">     * content approximately). Use inverse warping in the second image to take an image close to the first</a>
<span class="sourceLineNo">797</span><a id="line.797">     * one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV</a>
<span class="sourceLineNo">798</span><a id="line.798">     * sample image_alignment.cpp that demonstrates the use of the function. Note that the function throws</a>
<span class="sourceLineNo">799</span><a id="line.799">     * an exception if algorithm does not converges.</a>
<span class="sourceLineNo">800</span><a id="line.800">     *</a>
<span class="sourceLineNo">801</span><a id="line.801">     * SEE:</a>
<span class="sourceLineNo">802</span><a id="line.802">     * computeECC, estimateAffine2D, estimateAffinePartial2D, findHomography</a>
<span class="sourceLineNo">803</span><a id="line.803">     * @return automatically generated</a>
<span class="sourceLineNo">804</span><a id="line.804">     */</a>
<span class="sourceLineNo">805</span><a id="line.805">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize) {</a>
<span class="sourceLineNo">806</span><a id="line.806">        return findTransformECC_0(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType, criteria.type, criteria.maxCount, criteria.epsilon, inputMask.nativeObj, gaussFiltSize);</a>
<span class="sourceLineNo">807</span><a id="line.807">    }</a>
<span class="sourceLineNo">808</span><a id="line.808"></a>
<span class="sourceLineNo">809</span><a id="line.809"></a>
<span class="sourceLineNo">810</span><a id="line.810">    //</a>
<span class="sourceLineNo">811</span><a id="line.811">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType = MOTION_AFFINE, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 50, 0.001), Mat inputMask = Mat())</a>
<span class="sourceLineNo">812</span><a id="line.812">    //</a>
<span class="sourceLineNo">813</span><a id="line.813"></a>
<span class="sourceLineNo">814</span><a id="line.814">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria, Mat inputMask) {</a>
<span class="sourceLineNo">815</span><a id="line.815">        return findTransformECC_1(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType, criteria.type, criteria.maxCount, criteria.epsilon, inputMask.nativeObj);</a>
<span class="sourceLineNo">816</span><a id="line.816">    }</a>
<span class="sourceLineNo">817</span><a id="line.817"></a>
<span class="sourceLineNo">818</span><a id="line.818">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria) {</a>
<span class="sourceLineNo">819</span><a id="line.819">        return findTransformECC_2(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType, criteria.type, criteria.maxCount, criteria.epsilon);</a>
<span class="sourceLineNo">820</span><a id="line.820">    }</a>
<span class="sourceLineNo">821</span><a id="line.821"></a>
<span class="sourceLineNo">822</span><a id="line.822">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType) {</a>
<span class="sourceLineNo">823</span><a id="line.823">        return findTransformECC_3(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj, motionType);</a>
<span class="sourceLineNo">824</span><a id="line.824">    }</a>
<span class="sourceLineNo">825</span><a id="line.825"></a>
<span class="sourceLineNo">826</span><a id="line.826">    public static double findTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix) {</a>
<span class="sourceLineNo">827</span><a id="line.827">        return findTransformECC_4(templateImage.nativeObj, inputImage.nativeObj, warpMatrix.nativeObj);</a>
<span class="sourceLineNo">828</span><a id="line.828">    }</a>
<span class="sourceLineNo">829</span><a id="line.829"></a>
<span class="sourceLineNo">830</span><a id="line.830"></a>
<span class="sourceLineNo">831</span><a id="line.831">    //</a>
<span class="sourceLineNo">832</span><a id="line.832">    // C++:  Mat cv::readOpticalFlow(String path)</a>
<span class="sourceLineNo">833</span><a id="line.833">    //</a>
<span class="sourceLineNo">834</span><a id="line.834"></a>
<span class="sourceLineNo">835</span><a id="line.835">    /**</a>
<span class="sourceLineNo">836</span><a id="line.836">     * Read a .flo file</a>
<span class="sourceLineNo">837</span><a id="line.837">     *</a>
<span class="sourceLineNo">838</span><a id="line.838">     *  @param path Path to the file to be loaded</a>
<span class="sourceLineNo">839</span><a id="line.839">     *</a>
<span class="sourceLineNo">840</span><a id="line.840">     *  The function readOpticalFlow loads a flow field from a file and returns it as a single matrix.</a>
<span class="sourceLineNo">841</span><a id="line.841">     *  Resulting Mat has a type CV_32FC2 - floating-point, 2-channel. First channel corresponds to the</a>
<span class="sourceLineNo">842</span><a id="line.842">     *  flow in the horizontal direction (u), second - vertical (v).</a>
<span class="sourceLineNo">843</span><a id="line.843">     * @return automatically generated</a>
<span class="sourceLineNo">844</span><a id="line.844">     */</a>
<span class="sourceLineNo">845</span><a id="line.845">    public static Mat readOpticalFlow(String path) {</a>
<span class="sourceLineNo">846</span><a id="line.846">        return new Mat(readOpticalFlow_0(path));</a>
<span class="sourceLineNo">847</span><a id="line.847">    }</a>
<span class="sourceLineNo">848</span><a id="line.848"></a>
<span class="sourceLineNo">849</span><a id="line.849"></a>
<span class="sourceLineNo">850</span><a id="line.850">    //</a>
<span class="sourceLineNo">851</span><a id="line.851">    // C++:  bool cv::writeOpticalFlow(String path, Mat flow)</a>
<span class="sourceLineNo">852</span><a id="line.852">    //</a>
<span class="sourceLineNo">853</span><a id="line.853"></a>
<span class="sourceLineNo">854</span><a id="line.854">    /**</a>
<span class="sourceLineNo">855</span><a id="line.855">     * Write a .flo to disk</a>
<span class="sourceLineNo">856</span><a id="line.856">     *</a>
<span class="sourceLineNo">857</span><a id="line.857">     *  @param path Path to the file to be written</a>
<span class="sourceLineNo">858</span><a id="line.858">     *  @param flow Flow field to be stored</a>
<span class="sourceLineNo">859</span><a id="line.859">     *</a>
<span class="sourceLineNo">860</span><a id="line.860">     *  The function stores a flow field in a file, returns true on success, false otherwise.</a>
<span class="sourceLineNo">861</span><a id="line.861">     *  The flow field must be a 2-channel, floating-point matrix (CV_32FC2). First channel corresponds</a>
<span class="sourceLineNo">862</span><a id="line.862">     *  to the flow in the horizontal direction (u), second - vertical (v).</a>
<span class="sourceLineNo">863</span><a id="line.863">     * @return automatically generated</a>
<span class="sourceLineNo">864</span><a id="line.864">     */</a>
<span class="sourceLineNo">865</span><a id="line.865">    public static boolean writeOpticalFlow(String path, Mat flow) {</a>
<span class="sourceLineNo">866</span><a id="line.866">        return writeOpticalFlow_0(path, flow.nativeObj);</a>
<span class="sourceLineNo">867</span><a id="line.867">    }</a>
<span class="sourceLineNo">868</span><a id="line.868"></a>
<span class="sourceLineNo">869</span><a id="line.869"></a>
<span class="sourceLineNo">870</span><a id="line.870">    //</a>
<span class="sourceLineNo">871</span><a id="line.871">    // C++:  Ptr_BackgroundSubtractorMOG2 cv::createBackgroundSubtractorMOG2(int history = 500, double varThreshold = 16, bool detectShadows = true)</a>
<span class="sourceLineNo">872</span><a id="line.872">    //</a>
<span class="sourceLineNo">873</span><a id="line.873"></a>
<span class="sourceLineNo">874</span><a id="line.874">    /**</a>
<span class="sourceLineNo">875</span><a id="line.875">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">876</span><a id="line.876">     *</a>
<span class="sourceLineNo">877</span><a id="line.877">     * @param history Length of the history.</a>
<span class="sourceLineNo">878</span><a id="line.878">     * @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model</a>
<span class="sourceLineNo">879</span><a id="line.879">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">880</span><a id="line.880">     * affect the background update.</a>
<span class="sourceLineNo">881</span><a id="line.881">     * @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the</a>
<span class="sourceLineNo">882</span><a id="line.882">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">883</span><a id="line.883">     * @return automatically generated</a>
<span class="sourceLineNo">884</span><a id="line.884">     */</a>
<span class="sourceLineNo">885</span><a id="line.885">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2(int history, double varThreshold, boolean detectShadows) {</a>
<span class="sourceLineNo">886</span><a id="line.886">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_0(history, varThreshold, detectShadows));</a>
<span class="sourceLineNo">887</span><a id="line.887">    }</a>
<span class="sourceLineNo">888</span><a id="line.888"></a>
<span class="sourceLineNo">889</span><a id="line.889">    /**</a>
<span class="sourceLineNo">890</span><a id="line.890">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">891</span><a id="line.891">     *</a>
<span class="sourceLineNo">892</span><a id="line.892">     * @param history Length of the history.</a>
<span class="sourceLineNo">893</span><a id="line.893">     * @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model</a>
<span class="sourceLineNo">894</span><a id="line.894">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">895</span><a id="line.895">     * affect the background update.</a>
<span class="sourceLineNo">896</span><a id="line.896">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">897</span><a id="line.897">     * @return automatically generated</a>
<span class="sourceLineNo">898</span><a id="line.898">     */</a>
<span class="sourceLineNo">899</span><a id="line.899">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2(int history, double varThreshold) {</a>
<span class="sourceLineNo">900</span><a id="line.900">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_1(history, varThreshold));</a>
<span class="sourceLineNo">901</span><a id="line.901">    }</a>
<span class="sourceLineNo">902</span><a id="line.902"></a>
<span class="sourceLineNo">903</span><a id="line.903">    /**</a>
<span class="sourceLineNo">904</span><a id="line.904">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">905</span><a id="line.905">     *</a>
<span class="sourceLineNo">906</span><a id="line.906">     * @param history Length of the history.</a>
<span class="sourceLineNo">907</span><a id="line.907">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">908</span><a id="line.908">     * affect the background update.</a>
<span class="sourceLineNo">909</span><a id="line.909">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">910</span><a id="line.910">     * @return automatically generated</a>
<span class="sourceLineNo">911</span><a id="line.911">     */</a>
<span class="sourceLineNo">912</span><a id="line.912">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2(int history) {</a>
<span class="sourceLineNo">913</span><a id="line.913">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_2(history));</a>
<span class="sourceLineNo">914</span><a id="line.914">    }</a>
<span class="sourceLineNo">915</span><a id="line.915"></a>
<span class="sourceLineNo">916</span><a id="line.916">    /**</a>
<span class="sourceLineNo">917</span><a id="line.917">     * Creates MOG2 Background Subtractor</a>
<span class="sourceLineNo">918</span><a id="line.918">     *</a>
<span class="sourceLineNo">919</span><a id="line.919">     * to decide whether a pixel is well described by the background model. This parameter does not</a>
<span class="sourceLineNo">920</span><a id="line.920">     * affect the background update.</a>
<span class="sourceLineNo">921</span><a id="line.921">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">922</span><a id="line.922">     * @return automatically generated</a>
<span class="sourceLineNo">923</span><a id="line.923">     */</a>
<span class="sourceLineNo">924</span><a id="line.924">    public static BackgroundSubtractorMOG2 createBackgroundSubtractorMOG2() {</a>
<span class="sourceLineNo">925</span><a id="line.925">        return BackgroundSubtractorMOG2.__fromPtr__(createBackgroundSubtractorMOG2_3());</a>
<span class="sourceLineNo">926</span><a id="line.926">    }</a>
<span class="sourceLineNo">927</span><a id="line.927"></a>
<span class="sourceLineNo">928</span><a id="line.928"></a>
<span class="sourceLineNo">929</span><a id="line.929">    //</a>
<span class="sourceLineNo">930</span><a id="line.930">    // C++:  Ptr_BackgroundSubtractorKNN cv::createBackgroundSubtractorKNN(int history = 500, double dist2Threshold = 400.0, bool detectShadows = true)</a>
<span class="sourceLineNo">931</span><a id="line.931">    //</a>
<span class="sourceLineNo">932</span><a id="line.932"></a>
<span class="sourceLineNo">933</span><a id="line.933">    /**</a>
<span class="sourceLineNo">934</span><a id="line.934">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">935</span><a id="line.935">     *</a>
<span class="sourceLineNo">936</span><a id="line.936">     * @param history Length of the history.</a>
<span class="sourceLineNo">937</span><a id="line.937">     * @param dist2Threshold Threshold on the squared distance between the pixel and the sample to decide</a>
<span class="sourceLineNo">938</span><a id="line.938">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">939</span><a id="line.939">     * @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the</a>
<span class="sourceLineNo">940</span><a id="line.940">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">941</span><a id="line.941">     * @return automatically generated</a>
<span class="sourceLineNo">942</span><a id="line.942">     */</a>
<span class="sourceLineNo">943</span><a id="line.943">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN(int history, double dist2Threshold, boolean detectShadows) {</a>
<span class="sourceLineNo">944</span><a id="line.944">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_0(history, dist2Threshold, detectShadows));</a>
<span class="sourceLineNo">945</span><a id="line.945">    }</a>
<span class="sourceLineNo">946</span><a id="line.946"></a>
<span class="sourceLineNo">947</span><a id="line.947">    /**</a>
<span class="sourceLineNo">948</span><a id="line.948">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">949</span><a id="line.949">     *</a>
<span class="sourceLineNo">950</span><a id="line.950">     * @param history Length of the history.</a>
<span class="sourceLineNo">951</span><a id="line.951">     * @param dist2Threshold Threshold on the squared distance between the pixel and the sample to decide</a>
<span class="sourceLineNo">952</span><a id="line.952">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">953</span><a id="line.953">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">954</span><a id="line.954">     * @return automatically generated</a>
<span class="sourceLineNo">955</span><a id="line.955">     */</a>
<span class="sourceLineNo">956</span><a id="line.956">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN(int history, double dist2Threshold) {</a>
<span class="sourceLineNo">957</span><a id="line.957">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_1(history, dist2Threshold));</a>
<span class="sourceLineNo">958</span><a id="line.958">    }</a>
<span class="sourceLineNo">959</span><a id="line.959"></a>
<span class="sourceLineNo">960</span><a id="line.960">    /**</a>
<span class="sourceLineNo">961</span><a id="line.961">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">962</span><a id="line.962">     *</a>
<span class="sourceLineNo">963</span><a id="line.963">     * @param history Length of the history.</a>
<span class="sourceLineNo">964</span><a id="line.964">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">965</span><a id="line.965">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">966</span><a id="line.966">     * @return automatically generated</a>
<span class="sourceLineNo">967</span><a id="line.967">     */</a>
<span class="sourceLineNo">968</span><a id="line.968">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN(int history) {</a>
<span class="sourceLineNo">969</span><a id="line.969">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_2(history));</a>
<span class="sourceLineNo">970</span><a id="line.970">    }</a>
<span class="sourceLineNo">971</span><a id="line.971"></a>
<span class="sourceLineNo">972</span><a id="line.972">    /**</a>
<span class="sourceLineNo">973</span><a id="line.973">     * Creates KNN Background Subtractor</a>
<span class="sourceLineNo">974</span><a id="line.974">     *</a>
<span class="sourceLineNo">975</span><a id="line.975">     * whether a pixel is close to that sample. This parameter does not affect the background update.</a>
<span class="sourceLineNo">976</span><a id="line.976">     * speed a bit, so if you do not need this feature, set the parameter to false.</a>
<span class="sourceLineNo">977</span><a id="line.977">     * @return automatically generated</a>
<span class="sourceLineNo">978</span><a id="line.978">     */</a>
<span class="sourceLineNo">979</span><a id="line.979">    public static BackgroundSubtractorKNN createBackgroundSubtractorKNN() {</a>
<span class="sourceLineNo">980</span><a id="line.980">        return BackgroundSubtractorKNN.__fromPtr__(createBackgroundSubtractorKNN_3());</a>
<span class="sourceLineNo">981</span><a id="line.981">    }</a>
<span class="sourceLineNo">982</span><a id="line.982"></a>
<span class="sourceLineNo">983</span><a id="line.983"></a>
<span class="sourceLineNo">984</span><a id="line.984"></a>
<span class="sourceLineNo">985</span><a id="line.985"></a>
<span class="sourceLineNo">986</span><a id="line.986">    // C++:  RotatedRect cv::CamShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">987</span><a id="line.987">    private static native double[] CamShift_0(long probImage_nativeObj, int window_x, int window_y, int window_width, int window_height, double[] window_out, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">988</span><a id="line.988"></a>
<span class="sourceLineNo">989</span><a id="line.989">    // C++:  int cv::meanShift(Mat probImage, Rect&amp; window, TermCriteria criteria)</a>
<span class="sourceLineNo">990</span><a id="line.990">    private static native int meanShift_0(long probImage_nativeObj, int window_x, int window_y, int window_width, int window_height, double[] window_out, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">991</span><a id="line.991"></a>
<span class="sourceLineNo">992</span><a id="line.992">    // C++:  int cv::buildOpticalFlowPyramid(Mat img, vector_Mat&amp; pyramid, Size winSize, int maxLevel, bool withDerivatives = true, int pyrBorder = BORDER_REFLECT_101, int derivBorder = BORDER_CONSTANT, bool tryReuseInputImage = true)</a>
<span class="sourceLineNo">993</span><a id="line.993">    private static native int buildOpticalFlowPyramid_0(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder, boolean tryReuseInputImage);</a>
<span class="sourceLineNo">994</span><a id="line.994">    private static native int buildOpticalFlowPyramid_1(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives, int pyrBorder, int derivBorder);</a>
<span class="sourceLineNo">995</span><a id="line.995">    private static native int buildOpticalFlowPyramid_2(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives, int pyrBorder);</a>
<span class="sourceLineNo">996</span><a id="line.996">    private static native int buildOpticalFlowPyramid_3(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, boolean withDerivatives);</a>
<span class="sourceLineNo">997</span><a id="line.997">    private static native int buildOpticalFlowPyramid_4(long img_nativeObj, long pyramid_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel);</a>
<span class="sourceLineNo">998</span><a id="line.998"></a>
<span class="sourceLineNo">999</span><a id="line.999">    // C++:  void cv::calcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, vector_Point2f prevPts, vector_Point2f&amp; nextPts, vector_uchar&amp; status, vector_float&amp; err, Size winSize = Size(21,21), int maxLevel = 3, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01), int flags = 0, double minEigThreshold = 1e-4)</a>
<span class="sourceLineNo">1000</span><a id="line.1000">    private static native void calcOpticalFlowPyrLK_0(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, int criteria_type, int criteria_maxCount, double criteria_epsilon, int flags, double minEigThreshold);</a>
<span class="sourceLineNo">1001</span><a id="line.1001">    private static native void calcOpticalFlowPyrLK_1(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, int criteria_type, int criteria_maxCount, double criteria_epsilon, int flags);</a>
<span class="sourceLineNo">1002</span><a id="line.1002">    private static native void calcOpticalFlowPyrLK_2(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">1003</span><a id="line.1003">    private static native void calcOpticalFlowPyrLK_3(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height, int maxLevel);</a>
<span class="sourceLineNo">1004</span><a id="line.1004">    private static native void calcOpticalFlowPyrLK_4(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj, double winSize_width, double winSize_height);</a>
<span class="sourceLineNo">1005</span><a id="line.1005">    private static native void calcOpticalFlowPyrLK_5(long prevImg_nativeObj, long nextImg_nativeObj, long prevPts_mat_nativeObj, long nextPts_mat_nativeObj, long status_mat_nativeObj, long err_mat_nativeObj);</a>
<span class="sourceLineNo">1006</span><a id="line.1006"></a>
<span class="sourceLineNo">1007</span><a id="line.1007">    // C++:  void cv::calcOpticalFlowFarneback(Mat prev, Mat next, Mat&amp; flow, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags)</a>
<span class="sourceLineNo">1008</span><a id="line.1008">    private static native void calcOpticalFlowFarneback_0(long prev_nativeObj, long next_nativeObj, long flow_nativeObj, double pyr_scale, int levels, int winsize, int iterations, int poly_n, double poly_sigma, int flags);</a>
<span class="sourceLineNo">1009</span><a id="line.1009"></a>
<span class="sourceLineNo">1010</span><a id="line.1010">    // C++:  double cv::computeECC(Mat templateImage, Mat inputImage, Mat inputMask = Mat())</a>
<span class="sourceLineNo">1011</span><a id="line.1011">    private static native double computeECC_0(long templateImage_nativeObj, long inputImage_nativeObj, long inputMask_nativeObj);</a>
<span class="sourceLineNo">1012</span><a id="line.1012">    private static native double computeECC_1(long templateImage_nativeObj, long inputImage_nativeObj);</a>
<span class="sourceLineNo">1013</span><a id="line.1013"></a>
<span class="sourceLineNo">1014</span><a id="line.1014">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize)</a>
<span class="sourceLineNo">1015</span><a id="line.1015">    private static native double findTransformECC_0(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType, int criteria_type, int criteria_maxCount, double criteria_epsilon, long inputMask_nativeObj, int gaussFiltSize);</a>
<span class="sourceLineNo">1016</span><a id="line.1016"></a>
<span class="sourceLineNo">1017</span><a id="line.1017">    // C++:  double cv::findTransformECC(Mat templateImage, Mat inputImage, Mat&amp; warpMatrix, int motionType = MOTION_AFFINE, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 50, 0.001), Mat inputMask = Mat())</a>
<span class="sourceLineNo">1018</span><a id="line.1018">    private static native double findTransformECC_1(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType, int criteria_type, int criteria_maxCount, double criteria_epsilon, long inputMask_nativeObj);</a>
<span class="sourceLineNo">1019</span><a id="line.1019">    private static native double findTransformECC_2(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType, int criteria_type, int criteria_maxCount, double criteria_epsilon);</a>
<span class="sourceLineNo">1020</span><a id="line.1020">    private static native double findTransformECC_3(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj, int motionType);</a>
<span class="sourceLineNo">1021</span><a id="line.1021">    private static native double findTransformECC_4(long templateImage_nativeObj, long inputImage_nativeObj, long warpMatrix_nativeObj);</a>
<span class="sourceLineNo">1022</span><a id="line.1022"></a>
<span class="sourceLineNo">1023</span><a id="line.1023">    // C++:  Mat cv::readOpticalFlow(String path)</a>
<span class="sourceLineNo">1024</span><a id="line.1024">    private static native long readOpticalFlow_0(String path);</a>
<span class="sourceLineNo">1025</span><a id="line.1025"></a>
<span class="sourceLineNo">1026</span><a id="line.1026">    // C++:  bool cv::writeOpticalFlow(String path, Mat flow)</a>
<span class="sourceLineNo">1027</span><a id="line.1027">    private static native boolean writeOpticalFlow_0(String path, long flow_nativeObj);</a>
<span class="sourceLineNo">1028</span><a id="line.1028"></a>
<span class="sourceLineNo">1029</span><a id="line.1029">    // C++:  Ptr_BackgroundSubtractorMOG2 cv::createBackgroundSubtractorMOG2(int history = 500, double varThreshold = 16, bool detectShadows = true)</a>
<span class="sourceLineNo">1030</span><a id="line.1030">    private static native long createBackgroundSubtractorMOG2_0(int history, double varThreshold, boolean detectShadows);</a>
<span class="sourceLineNo">1031</span><a id="line.1031">    private static native long createBackgroundSubtractorMOG2_1(int history, double varThreshold);</a>
<span class="sourceLineNo">1032</span><a id="line.1032">    private static native long createBackgroundSubtractorMOG2_2(int history);</a>
<span class="sourceLineNo">1033</span><a id="line.1033">    private static native long createBackgroundSubtractorMOG2_3();</a>
<span class="sourceLineNo">1034</span><a id="line.1034"></a>
<span class="sourceLineNo">1035</span><a id="line.1035">    // C++:  Ptr_BackgroundSubtractorKNN cv::createBackgroundSubtractorKNN(int history = 500, double dist2Threshold = 400.0, bool detectShadows = true)</a>
<span class="sourceLineNo">1036</span><a id="line.1036">    private static native long createBackgroundSubtractorKNN_0(int history, double dist2Threshold, boolean detectShadows);</a>
<span class="sourceLineNo">1037</span><a id="line.1037">    private static native long createBackgroundSubtractorKNN_1(int history, double dist2Threshold);</a>
<span class="sourceLineNo">1038</span><a id="line.1038">    private static native long createBackgroundSubtractorKNN_2(int history);</a>
<span class="sourceLineNo">1039</span><a id="line.1039">    private static native long createBackgroundSubtractorKNN_3();</a>
<span class="sourceLineNo">1040</span><a id="line.1040"></a>
<span class="sourceLineNo">1041</span><a id="line.1041">}</a>




























































</pre>
</div>
</main>
</body>
</html>
